{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35c03663",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine datasets\n",
    "import glob\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def merge_pt_files(pt_paths):\n",
    "    merged = {}\n",
    "    for path in pt_paths:\n",
    "        data = torch.load(path, map_location='cpu')\n",
    "        if not merged:\n",
    "            merged = {k: [v] for k, v in data.items()}\n",
    "            continue\n",
    "        if data.keys() != merged.keys():\n",
    "            print(data.keys(),merged.keys())\n",
    "            raise ValueError(f\"Key mismatch in {path}\")\n",
    "        for k, v in data.items():\n",
    "            merged[k].append(v)\n",
    "    for k, tensors in merged.items():\n",
    "        try:\n",
    "            merged[k] = torch.cat(tensors, dim=0)\n",
    "        except RuntimeError:\n",
    "            merged[k] = tensors \n",
    "    return merged\n",
    "\n",
    "pt_files = glob.glob(\"torchfem_dataset/panel_plasticity/*.pt\")\n",
    "combined = merge_pt_files(pt_files)\n",
    "torch.save(combined, \"torchfem_dataset/panel_plasticity/combined.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e720bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aluminum\n",
      "steel\n",
      "aluminum\n",
      "steel\n",
      "aluminum\n",
      "aluminum\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "aluminum\n",
      "aluminum\n",
      "steel\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "CFRP\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "steel\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "aluminum\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "aluminum\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "aluminum\n",
      "aluminum\n",
      "aluminum\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "steel\n",
      "CFRP\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "aluminum\n",
      "aluminum\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "Wrote 124 samples to ../torchfem_dataset/panel_processed.pt\n"
     ]
    }
   ],
   "source": [
    "## Modify Dataset with Material Labels\n",
    "import torch\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "mat_df = pd.read_csv(\"../torchfem_dataset/tube/materials.csv\")\n",
    "\n",
    "files = glob.glob('../torchfem_dataset/panel_plasticity/simulation_dump*.pt')\n",
    "\n",
    "material_map = {'concrete':0,'steel':1,'aluminum':2,'CFRP':3}\n",
    "\n",
    "def stiffness_to_edges(K, num_nodes, dof_per_node=3):\n",
    "    K = K.coalesce()\n",
    "    dof_rows, dof_cols = K.indices()\n",
    "    node_rows = torch.div(dof_rows, dof_per_node, rounding_mode='floor')\n",
    "    node_cols = torch.div(dof_cols, dof_per_node, rounding_mode='floor')\n",
    "    block_ids = node_rows * num_nodes + node_cols\n",
    "\n",
    "    uniq_blocks, inverse = torch.unique(block_ids, return_inverse=True)\n",
    "    local_row = dof_rows % dof_per_node\n",
    "    local_col = dof_cols % dof_per_node\n",
    "    flat_offsets = inverse * (dof_per_node * dof_per_node) + local_row * dof_per_node + local_col\n",
    "\n",
    "    edge_attr_flat = torch.zeros(\n",
    "        uniq_blocks.numel() * dof_per_node * dof_per_node,\n",
    "        dtype=K.values().dtype,\n",
    "        device=K.values().device,\n",
    "    )\n",
    "    edge_attr_flat.scatter_add_(0, flat_offsets, K.values())\n",
    "    edge_attr = edge_attr_flat.view(uniq_blocks.numel(), dof_per_node, dof_per_node)\n",
    "\n",
    "    senders = torch.div(uniq_blocks, num_nodes, rounding_mode='floor')\n",
    "    receivers = uniq_blocks % num_nodes\n",
    "    return senders.long(), receivers.long(), edge_attr.reshape(uniq_blocks.numel(), -1).float()\n",
    "\n",
    "def build_graph_sample(material,sim, t_stride=1):\n",
    "    nodes = sim[\"nodes\"].float()\n",
    "    u_hist = sim[\"u_history\"][::t_stride].float()\n",
    "    f_hist = sim[\"forces\"][::t_stride].float()\n",
    "    dirichlet = sim.get(\"dirichlet_disp\", torch.zeros_like(nodes)).float()\n",
    "    constraints = sim.get(\"boundary\", sim.get(\"constraints\", torch.zeros_like(nodes, dtype=torch.bool))).float()\n",
    "\n",
    "    static = torch.cat([nodes, dirichlet, constraints], dim=-1)\n",
    "    static = static.unsqueeze(0).expand(u_hist.size(0), -1, -1)\n",
    "    dynamic = torch.cat([u_hist, f_hist], dim=-1)\n",
    "    node_features = torch.cat([static, dynamic], dim=-1)\n",
    "\n",
    "    senders, receivers, edge_features = stiffness_to_edges(\n",
    "        sim[\"stiffness\"],\n",
    "        num_nodes=nodes.size(0),\n",
    "        dof_per_node=nodes.size(1),\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"node_features\": node_features,\n",
    "        \"edge_features\": edge_features,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"target\": u_hist,\n",
    "    }\n",
    "\n",
    "def preprocess_panel_dataset(src_dir=\"../torchfem_dataset/panel_plasticity\",\n",
    "                             dst_path=\"../torchfem_dataset/panel_processed.pt\",\n",
    "                             t_stride=1):\n",
    "    src_dir = Path(src_dir)\n",
    "    samples = []\n",
    "    for pt_file in sorted(src_dir.glob(\"simulation_dump*.pt\")):\n",
    "        idx = int(str(pt_file).split('simulation_dump_')[1].split('.pt')[0])\n",
    "        material = mat_df[mat_df['0']==idx]\n",
    "        mat = material['1'].item()\n",
    "        sim = torch.load(pt_file, map_location=\"cpu\")\n",
    "        samples.append(build_graph_sample(mat,sim, t_stride=t_stride))\n",
    "    Path(dst_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    #torch.save(samples, dst_path)\n",
    "    print(f\"Wrote {len(samples)} samples to {dst_path}\")\n",
    "\n",
    "# Run once to create the processed file\n",
    "preprocess_panel_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fda6e759",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     93\u001b[39m         samples.append(data)\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m samples\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m dataset = \u001b[43mbuild_hetero_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m     \u001b[49m\u001b[43msrc_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../torchfem_dataset/tube\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m     \u001b[49m\u001b[43mmaterials_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../torchfem_dataset/tube/materials.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m     \u001b[49m\u001b[43mt_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# torch.save(dataset, \"../torchfem_dataset/panel_plasticity/hetero_panel.pt\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 92\u001b[39m, in \u001b[36mbuild_hetero_dataset\u001b[39m\u001b[34m(src_dir, materials_csv, t_stride)\u001b[39m\n\u001b[32m     90\u001b[39m     sim[\u001b[33m\"\u001b[39m\u001b[33mu_history\u001b[39m\u001b[33m\"\u001b[39m] = sim[\u001b[33m\"\u001b[39m\u001b[33mu_history\u001b[39m\u001b[33m\"\u001b[39m][::t_stride]\n\u001b[32m     91\u001b[39m     sim[\u001b[33m\"\u001b[39m\u001b[33mforces\u001b[39m\u001b[33m\"\u001b[39m] = sim[\u001b[33m\"\u001b[39m\u001b[33mforces\u001b[39m\u001b[33m\"\u001b[39m][::t_stride]\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     data = \u001b[43mbuild_hetero_graph_for_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaterial_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaterial_vocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     samples.append(data)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m samples\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mbuild_hetero_graph_for_sim\u001b[39m\u001b[34m(sim, material_label, material_vocab, edge_mode)\u001b[39m\n\u001b[32m     62\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mapplies_to_rev\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmat\u001b[39m\u001b[33m\"\u001b[39m].edge_index = mat_to_nodes.flip(\u001b[32m0\u001b[39m)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# optional node adjacency edges\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m ei = \u001b[43mstiffness_to_node_adj_edge_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstiffness\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdof_per_node\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33madjacent\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m\"\u001b[39m].edge_index = ei\n\u001b[32m     67\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33madjacent_rev\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m\"\u001b[39m].edge_index = ei.flip(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mstiffness_to_node_adj_edge_index\u001b[39m\u001b[34m(K, num_nodes, dof_per_node)\u001b[39m\n\u001b[32m     27\u001b[39m mask = ei[\u001b[32m0\u001b[39m] != ei[\u001b[32m1\u001b[39m]\n\u001b[32m     28\u001b[39m ei = ei[:, mask]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m ei = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ei\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bm_tu\\Desktop\\gnn\\gnn_312\\Lib\\site-packages\\torch\\_jit_internal.py:622\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bm_tu\\Desktop\\gnn\\gnn_312\\Lib\\site-packages\\torch\\_jit_internal.py:622\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bm_tu\\Desktop\\gnn\\gnn_312\\Lib\\site-packages\\torch\\functional.py:1102\u001b[39m, in \u001b[36m_return_output\u001b[39m\u001b[34m(input, sorted, return_inverse, return_counts, dim)\u001b[39m\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[32m   1100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[32m-> \u001b[39m\u001b[32m1102\u001b[39m output, _, _ = \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bm_tu\\Desktop\\gnn\\gnn_312\\Lib\\site-packages\\torch\\functional.py:987\u001b[39m, in \u001b[36m_unique_impl\u001b[39m\u001b[34m(input, sorted, return_inverse, return_counts, dim)\u001b[39m\n\u001b[32m    976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    977\u001b[39m         unique,\n\u001b[32m    978\u001b[39m         (\u001b[38;5;28minput\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    983\u001b[39m         dim=dim,\n\u001b[32m    984\u001b[39m     )\n\u001b[32m    986\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m987\u001b[39m     output, inverse_indices, counts = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique_dim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    995\u001b[39m     output, inverse_indices, counts = torch._unique2(\n\u001b[32m    996\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    997\u001b[39m         \u001b[38;5;28msorted\u001b[39m=\u001b[38;5;28msorted\u001b[39m,\n\u001b[32m    998\u001b[39m         return_inverse=return_inverse,\n\u001b[32m    999\u001b[39m         return_counts=return_counts,\n\u001b[32m   1000\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "## PyG HeteroData\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import pandas as pd\n",
    "\n",
    "def load_material_vocab(materials_csv: str) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    df = pd.read_csv(materials_csv, header=None, names=[\"sim_id\", \"label\"])\n",
    "    labels = sorted(df[\"label\"].astype(str).unique().tolist())\n",
    "    vocab = {lbl: i for i, lbl in enumerate(labels)}\n",
    "    sim_to_label = {int(r.sim_id): str(r.label) for _, r in df.iterrows()}\n",
    "    return vocab, sim_to_label\n",
    "\n",
    "def one_hot(label: str, vocab: Dict[str, int], device=None, dtype=torch.float) -> torch.Tensor:\n",
    "    vec = torch.zeros(len(vocab), dtype=dtype, device=device)\n",
    "    vec[vocab[label]] = 1.0\n",
    "    return vec\n",
    "\n",
    "def stiffness_to_node_adj_edge_index(K: torch.Tensor, num_nodes: int, dof_per_node: int = 3) -> torch.Tensor:\n",
    "    K = K.coalesce()\n",
    "    dof_rows, dof_cols = K.indices()\n",
    "    node_rows = torch.div(dof_rows, dof_per_node, rounding_mode=\"floor\")\n",
    "    node_cols = torch.div(dof_cols, dof_per_node, rounding_mode=\"floor\")\n",
    "    ei = torch.stack([node_rows.long(), node_cols.long()], dim=0)\n",
    "    mask = ei[0] != ei[1]\n",
    "    ei = ei[:, mask]\n",
    "    ei = torch.unique(ei, dim=1)\n",
    "    return ei\n",
    "\n",
    "def build_hetero_graph_for_sim(\n",
    "    sim: Dict[str, torch.Tensor],\n",
    "    material_label: str,\n",
    "    material_vocab: Dict[str, int],\n",
    "    edge_mode: str = \"from_K\"  # \"from_K\" or \"knn\" or \"none\"\n",
    "    ) -> HeteroData:\n",
    "    nodes = sim[\"nodes\"].float()        # [N, 3]\n",
    "    u_hist = sim[\"u_history\"].float()   # [T, N, 3]\n",
    "    f_hist = sim[\"forces\"].float()      # [T, N, 3]\n",
    "    dirichlet = sim.get(\"dirichlet_disp\", torch.zeros_like(nodes)).float()  # [N, 3]\n",
    "    constraints = sim.get(\"boundary\", sim.get(\"constraints\", torch.zeros_like(nodes, dtype=torch.bool))).float()\n",
    "\n",
    "    data = HeteroData()\n",
    "\n",
    "    # node-type features\n",
    "    data[\"node\"].pos = nodes                              # [N, d]\n",
    "    data[\"node\"].dirichlet = dirichlet                    # [N, dof]\n",
    "    data[\"node\"].bc_mask = constraints                    # [N, dof]\n",
    "    data[\"node\"].u_hist = u_hist                          # [T, N, dof]\n",
    "    data[\"node\"].f_hist = f_hist                          # [T, N, dof]\n",
    "\n",
    "    # material-type node (one per sample)\n",
    "    mat_oh = one_hot(material_label, material_vocab, device=nodes.device)\n",
    "    data[\"mat\"].x = mat_oh.unsqueeze(0)                   # [1, C]\n",
    "    data[\"mat\"].index = torch.tensor([material_vocab[material_label]], dtype=torch.long)\n",
    "\n",
    "    # incidence from material to all nodes\n",
    "    N = nodes.size(0)\n",
    "    mat_to_nodes = torch.stack([torch.zeros(N, dtype=torch.long), torch.arange(N, dtype=torch.long)], dim=0)  # [2, N]\n",
    "    data[\"mat\", \"applies_to\", \"node\"].edge_index = mat_to_nodes\n",
    "    data[\"node\", \"applies_to_rev\", \"mat\"].edge_index = mat_to_nodes.flip(0)\n",
    "\n",
    "    # optional node adjacency edges\n",
    "    ei = stiffness_to_node_adj_edge_index(sim[\"stiffness\"], num_nodes=N, dof_per_node=nodes.size(1))\n",
    "    data[\"node\", \"adjacent\", \"node\"].edge_index = ei\n",
    "    data[\"node\", \"adjacent_rev\", \"node\"].edge_index = ei.flip(0)\n",
    "\n",
    "    # optional edge features (e.g., relative displacement or unit scalar)\n",
    "    if (\"node\", \"adjacent\", \"node\") in data.edge_types:\n",
    "        ei = data[\"node\", \"adjacent\", \"node\"].edge_index\n",
    "        data[\"node\", \"adjacent\", \"node\"].edge_attr = (nodes[ei[1]] - nodes[ei[0]]).float()  # [E, d]\n",
    "\n",
    "    # training targets\n",
    "    data[\"node\"].y = u_hist  # [T, N, dof]\n",
    "    #data[\"node\"].y = u_hist  # [T, N, dof] #TODO: add stress history\n",
    "\n",
    "    return data\n",
    "\n",
    "def build_hetero_dataset(\n",
    "    src_dir: str = \"../torchfem_dataset/panel_plasticity\",\n",
    "    materials_csv: str = \"../torchfem_dataset/panel_plasticity/materials.csv\",\n",
    "    t_stride: int = 1,\n",
    "    ) -> List[HeteroData]:\n",
    "    vocab, sim_to_label = load_material_vocab(materials_csv)\n",
    "    samples: List[HeteroData] = []\n",
    "    for pt_file in sorted(Path(src_dir).glob(\"simulation_dump*.pt\")):\n",
    "        idx = int(str(pt_file).split(\"simulation_dump_\")[1].split(\".pt\")[0])\n",
    "        label = sim_to_label[idx]\n",
    "        sim = torch.load(pt_file, map_location=\"cpu\")\n",
    "        sim[\"u_history\"] = sim[\"u_history\"][::t_stride]\n",
    "        sim[\"forces\"] = sim[\"forces\"][::t_stride]\n",
    "        data = build_hetero_graph_for_sim(sim, material_label=label, material_vocab=vocab)\n",
    "        samples.append(data)\n",
    "    return samples\n",
    "\n",
    "dataset = build_hetero_dataset(\n",
    "     src_dir=\"../torchfem_dataset/tube\",\n",
    "     materials_csv=\"../torchfem_dataset/tube/materials.csv\",\n",
    "     t_stride=1)\n",
    "# torch.save(dataset, \"../torchfem_dataset/panel_plasticity/hetero_panel.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9cc12ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1664, 3])\n",
      "torch.Size([200, 775, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.load('../base/torchfem_dataset/processed/simulation_dump_3.pt')\n",
    "print(data['nodes'].shape)\n",
    "print(data['stress_history'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269910fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_10.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_100.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_101.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_102.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_103.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_104.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_105.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_106.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_107.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_108.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_11.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_110.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_111.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_112.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_113.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_114.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_115.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_117.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_118.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_119.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_12.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_120.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_121.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_122.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_123.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_124.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_125.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_126.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_127.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_128.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_129.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_13.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_130.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_133.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_134.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_135.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_136.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_137.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_138.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_139.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_14.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_140.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_141.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_142.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_143.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_144.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_145.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_147.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_148.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_149.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_15.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_150.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_17.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_18.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_2.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_20.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_22.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_24.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_25.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_27.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_28.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_3.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_30.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_31.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_32.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_33.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_37.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_38.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_39.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_4.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_40.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_41.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_42.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_43.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_44.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_46.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_47.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_48.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_49.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_5.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_50.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_51.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_52.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_53.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_54.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_56.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_58.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_59.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_6.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_60.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_62.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_63.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_64.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_65.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_66.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_67.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_68.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_69.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_7.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_70.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_71.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_72.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_73.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_74.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_76.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_79.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_8.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_80.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_81.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_83.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_84.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_85.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_86.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_87.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_88.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_9.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_90.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_91.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_92.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_93.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_95.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_96.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_97.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_98.pt\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "## PyG Graph with Mesh & Element Nodes\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import pandas as pd\n",
    "\n",
    "# Material encoding (1-h)\n",
    "def load_material_vocab(materials_csv: str) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    # CSV: idx,label\n",
    "    df = pd.read_csv(materials_csv, header=None, names=[\"sim_id\", \"label\"])\n",
    "    #labels = sorted(df[\"label\"].astype(str).unique().tolist())\n",
    "    labels = ['concrete','steel','aluminum','CFRP'] #0,1,2,3 fixed material labels for now\n",
    "    vocab = {lbl: i for i, lbl in enumerate(labels)}\n",
    "    sim_to_label = {int(r.sim_id): str(r.label) for _, r in df.iterrows()}\n",
    "    return vocab, sim_to_label\n",
    "\n",
    "def one_hot(label: str, vocab: Dict[str, int], device=None, dtype=torch.float) -> torch.Tensor:\n",
    "    vec = torch.zeros(len(vocab), dtype=dtype, device=device)\n",
    "    vec[vocab[label]] = 1.0\n",
    "    return vec\n",
    "\n",
    "def stiffness_to_node_adj_edge_index(K: torch.Tensor, num_nodes: int, dof_per_node: int = 3) -> torch.Tensor: #mesh-mesh nodes\n",
    "    K = K.coalesce()\n",
    "    dof_rows, dof_cols = K.indices()\n",
    "    node_rows = torch.div(dof_rows, dof_per_node, rounding_mode=\"floor\")\n",
    "    node_cols = torch.div(dof_cols, dof_per_node, rounding_mode=\"floor\")\n",
    "    ei = torch.stack([node_rows.long(), node_cols.long()], dim=0)\n",
    "    mask = ei[0] != ei[1]\n",
    "    ei = ei[:, mask]\n",
    "    ei = torch.unique(ei, dim=1)\n",
    "    return ei\n",
    "\n",
    "def incidence_edges_from_conn(conn: np.ndarray, nodes: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    Nc, Nv = conn.shape\n",
    "    c_idx = np.repeat(np.arange(Nc, dtype=np.int64), Nv)\n",
    "    n_idx = conn.reshape(-1)\n",
    "    edge_index = torch.from_numpy(np.vstack([c_idx, n_idx])).long()\n",
    "    node_tensor = nodes.to(edge_index.device)\n",
    "    conn_tensor = torch.from_numpy(conn).long().to(edge_index.device)\n",
    "    #edge attribute -> mesh to element centroid in xyz\n",
    "    elem_nodes = node_tensor[conn_tensor]\n",
    "    centroids = elem_nodes.mean(dim=1, keepdim=True)\n",
    "    rel_disp = (elem_nodes - centroids).reshape(-1, elem_nodes.size(-1))\n",
    "\n",
    "    return edge_index, rel_disp\n",
    "\n",
    "# Connectivity\n",
    "# mesh nodes <-> mesh nodes\n",
    "# mesh nodes <-> element nodes\n",
    "\n",
    "def data_to_graph(idx, path:str,materials_csv:str,device):\n",
    "    data = HeteroData()\n",
    "    vocab, sim_to_label = load_material_vocab(materials_csv)\n",
    "    simdata = torch.load(path)\n",
    "    idx = idx\n",
    "    conn = simdata[\"elements\"]\n",
    "    conn = conn.cpu().numpy() if isinstance(conn, torch.Tensor) else np.asarray(conn)\n",
    "    nodes = simdata['nodes']\n",
    "    label = sim_to_label[idx]\n",
    "    c2n_ei, c2n_w = incidence_edges_from_conn(conn,nodes)  # [2, E_cn], [E_cn, 1]\n",
    "    \n",
    "    # mesh node properties: positions, internal forces, BC, dirichlet displacement\n",
    "    ##TODO: add external forces\n",
    "    data['nodes'].pos = nodes #                                             [N,3]\n",
    "    data['nodes'].f_ts = simdata['forces'] #forces in timeseries format     [T,N,3]\n",
    "    data['nodes'].bc = simdata['boundary'] #                                [N,3]\n",
    "    data['nodes'].dr = simdata['dirichlet_disp'] #dirichlet displacement    [N,3]\n",
    "\n",
    "    # element node properties: material, stiffness matrix\n",
    "    data['elements'].material = one_hot(label, vocab, device=device).unsqueeze(0).repeat(int(conn.shape[0]), 1) # [E,len(materials)]\n",
    "    #data['elements'].stiffness = #stiffness is a learned feature\n",
    "\n",
    "    # target properties\n",
    "    # mesh: displacement over time\n",
    "    # element: stress, damage state\n",
    "    data['nodes'].u_ts = simdata['u_history']\n",
    "    data['elements'].s_ts = simdata['stress_history']\n",
    "    data['elements'].d_ts = simdata['state']\n",
    "\n",
    "    # edges: connectivity mesh-mesh, mesh-element\n",
    "    # mesh-element: distance to element centroid\n",
    "    data[\"elements\", \"contributes\", \"nodes\"].edge_index = c2n_ei\n",
    "    data[\"elements\", \"contributes\", \"nodes\"].edge_attr = c2n_w\n",
    "    data[\"nodes\", \"belongs_to\", \"elements\"].edge_index = c2n_ei.flip(0)\n",
    "    data[\"nodes\", \"belongs_to\", \"elements\"].edge_attr = -c2n_w\n",
    "    data['elements'].num_nodes = simdata['stress_history'].size(1)\n",
    "\n",
    "    # mesh-mesh: distance\n",
    "    ei = stiffness_to_node_adj_edge_index(simdata[\"stiffness\"], num_nodes=nodes.size(0), dof_per_node=nodes.size(1))\n",
    "    data[\"nodes\", \"adjacent\", \"nodes\"].edge_index = ei\n",
    "    data[\"nodes\", \"adjacent_rev\", \"nodes\"].edge_index = ei.flip(0)\n",
    "    data[\"nodes\", \"adjacent\", \"nodes\"].edge_attr = (nodes[ei[1]] - nodes[ei[0]]).float()\n",
    "\n",
    "    #data['elements'].edge_index = simdata['elements'] #mesh-element [E,8]\n",
    "    #data['nodes'].edge_index = stiffness_to_node_adj_edge_index(simdata[\"stiffness\"], num_nodes=nodes.size(0), dof_per_node=nodes.size(1)) #from stiffness matrix, only connectivity\n",
    "\n",
    "    #print(data['nodes'].num_nodes)                              # N\n",
    "    #print(data['elements'].num_nodes)                           # E\n",
    "    #print(data.num_edges)                                       # 2*((E*num_vertices)+())\n",
    "    #print(data['nodes','adjacent','nodes'].num_edges)           # \n",
    "    #print(data['nodes','adjacent_rev','nodes'].num_edges)       #\n",
    "    #print(data['elements','contributes','nodes'].num_edges)     # E*num_vertices\n",
    "    #print(data['nodes','belongs_to','elements'].num_edges)      # E*num_vertices\n",
    "\n",
    "    #data = data.pin_memory()\n",
    "    data = data.to(device)\n",
    "    return data\n",
    "\n",
    "#data_to_graph('../base/torchfem_dataset/processed/simulation_dump_3.pt','../base/torchfem_dataset/processed/mat.csv',device)\n",
    "\n",
    "def generate_dataset(data_dir:str,materials_csv:str):\n",
    "    device = torch.device('cpu')\n",
    "    files = sorted(Path(data_dir).glob(\"simulation_dump*.pt\"))\n",
    "    samples = []\n",
    "    for file in files:\n",
    "        idx = int(str(file).split(\"simulation_dump_\")[1].split(\".pt\")[0])\n",
    "        data = data_to_graph(idx,file,materials_csv,device)\n",
    "        samples.append(data)\n",
    "        print(file)\n",
    "    print(len(files))\n",
    "    return samples\n",
    "\n",
    "dataset = generate_dataset('../base/torchfem_dataset/panel_euler/panel_plasticity','../base/torchfem_dataset/processed/mat.csv')\n",
    "torch.save(dataset, \"../base/torchfem_dataset/processed/panel_combined.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ac5d979e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4300.0, 4400.0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "forces = dataset[0]['nodes']['f_ts'][10]*5e-4\n",
    "disp = dataset[0]['nodes']['u_ts'][10]\n",
    "boundary = dataset[0]['nodes']['bc']*5\n",
    "plt.plot(boundary)\n",
    "plt.plot(forces,'r')\n",
    "plt.plot(disp,'k')\n",
    "plt.xlim(4300,4400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd81b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['nodes', 'elements'], [('elements', 'contributes', 'nodes'), ('nodes', 'belongs_to', 'elements'), ('nodes', 'adjacent', 'nodes'), ('nodes', 'adjacent_rev', 'nodes')])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#print(graph.keys)\u001b[39;00m\n\u001b[32m     17\u001b[39m types = graph.node_types\n\u001b[32m     19\u001b[39m gnn = GNN(conv_name=\u001b[33m'\u001b[39m\u001b[33mhgt\u001b[39m\u001b[33m'\u001b[39m,in_dim=\u001b[32m500\u001b[39m,n_hid=\u001b[32m64\u001b[39m,n_heads=\u001b[32m2\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m           n_layers=\u001b[32m3\u001b[39m,dropout=\u001b[32m0.1\u001b[39m,num_types=\u001b[38;5;28mlen\u001b[39m(types),num_relations=\u001b[38;5;28mlen\u001b[39m(\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)+\u001b[32m1\u001b[39m)\n\u001b[32m     21\u001b[39m matcher = Matcher(\u001b[32m64\u001b[39m).to(device)\n\u001b[32m     22\u001b[39m model = nn.Sequential(gnn,matcher)\n",
      "\u001b[31mTypeError\u001b[39m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "## Heterogeneous Graph Transformer - Dynamic over timesteps\n",
    "from torch_geometric.data import DataLoader\n",
    "from forward_src.hgt_conv import *\n",
    "from forward_src.hgt_model import GNN, Matcher\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "dataset = torch.load(\"../base/torchfem_dataset/processed/panel_combined.pt\")\n",
    "print(dataset[0].metadata())\n",
    "device = 'cpu'\n",
    "graph = dataset[1]\n",
    "#print(graph.keys)\n",
    "\n",
    "types = graph.node_types\n",
    "\n",
    "gnn = GNN(conv_name='hgt',in_dim=len(graph['nodes'].values[0]),n_hid=64,n_heads=2,\n",
    "          n_layers=3,dropout=0.1,num_types=len(types),num_relations=len(graph.edge_types())+1)\n",
    "matcher = Matcher(64).to(device)\n",
    "model = nn.Sequential(gnn,matcher)\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 1000, eta_min=1e-6)\n",
    "loader = DataLoader(dataset)\n",
    "\n",
    "def mask_softmax(pred, size):\n",
    "    loss = 0\n",
    "    stx = 0\n",
    "    for l in size:\n",
    "        loss += torch.log_softmax(pred[stx: stx + l], dim=-1)[0] / np.log(l)\n",
    "        stx += l\n",
    "    return -loss\n",
    "\n",
    "stats = []\n",
    "res = []\n",
    "best_val   = 0\n",
    "train_step = 1500\n",
    "\n",
    "sample = next(iter(loader))\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    torch.cuda.empty_cache()\n",
    "    break\n",
    "    for _ in range(2):\n",
    "        for node_feature, node_type, edge_time, edge_index, edge_type, ylabel in train_data:\n",
    "            node_rep = gnn.forward(node_feature.to(device), node_type.to(device), \\\n",
    "                                   edge_time.to(device), edge_index.to(device), edge_type.to(device))\n",
    "            author_key = []\n",
    "            paper_key  = []\n",
    "            key_size   = []\n",
    "            for paper_id in ylabel:\n",
    "                author_ids  = ylabel[paper_id]\n",
    "                paper_key  += [np.repeat(paper_id, len(author_ids))]\n",
    "                author_key += [author_ids]\n",
    "                key_size   += [len(author_ids)]\n",
    "            paper_key  = torch.LongTensor(np.concatenate(paper_key)).to(device)\n",
    "            author_key = torch.LongTensor(np.concatenate(author_key)).to(device)\n",
    "\n",
    "            train_paper_vecs  = node_rep[paper_key]\n",
    "            train_author_vecs = node_rep[author_key]\n",
    "            res = matcher.forward(train_author_vecs, train_paper_vecs, pair=True)\n",
    "            loss = mask_softmax(res, key_size)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            torch.cuda.empty_cache()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses += [loss.cpu().detach().tolist()]\n",
    "            train_step += 1\n",
    "            scheduler.step(train_step)\n",
    "            del res, loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        node_feature, node_type, edge_time, edge_index, edge_type, ylabel = valid_data\n",
    "        node_rep = gnn.forward(node_feature.to(device), node_type.to(device), \\\n",
    "                                   edge_time.to(device), edge_index.to(device), edge_type.to(device))\n",
    "\n",
    "        author_key = []\n",
    "        paper_key  = []\n",
    "        key_size   = []\n",
    "        for paper_id in ylabel:\n",
    "            author_ids  = ylabel[paper_id]\n",
    "            paper_key  += [np.repeat(paper_id, len(author_ids))]\n",
    "            author_key += [author_ids]\n",
    "            key_size   += [len(author_ids)]\n",
    "        paper_key  = torch.LongTensor(np.concatenate(paper_key)).to(device)\n",
    "        author_key = torch.LongTensor(np.concatenate(author_key)).to(device)\n",
    "        \n",
    "        valid_paper_vecs  = node_rep[paper_key]\n",
    "        valid_author_vecs = node_rep[author_key]\n",
    "        res = matcher.forward(valid_author_vecs, valid_paper_vecs, pair=True)\n",
    "        loss = mask_softmax(res, key_size)\n",
    "        '''\n",
    "            Calculate Valid NDCG. Update the best model based on highest NDCG score.\n",
    "        '''\n",
    "        valid_res = []\n",
    "        ser = 0\n",
    "        for s in key_size:\n",
    "            p = res[ser: ser + s]\n",
    "            l = torch.zeros(s)\n",
    "            l[0] = 1\n",
    "            r = l[p.argsort(descending = True)]\n",
    "            valid_res += [r.cpu().detach().tolist()]\n",
    "            ser += s\n",
    "        valid_ndcg = np.average([ndcg_at_k(resi, len(resi)) for resi in valid_res])\n",
    "        valid_mrr  = np.average(mean_reciprocal_rank(valid_res))\n",
    "        \n",
    "        if valid_ndcg > best_val:\n",
    "            best_val = valid_ndcg\n",
    "            torch.save(model, os.path.join(args.model_dir, args.task_name + '_' + args.conv_name))\n",
    "            print('UPDATE!!!')\n",
    "        \n",
    "        st = time.time()\n",
    "        print((\"Epoch: %d (%.1fs)  LR: %.5f Train Loss: %.2f  Valid Loss: %.2f  Valid NDCG: %.4f  Valid MRR: %.4f\") % \\\n",
    "              (epoch, (st-et), optimizer.param_groups[0]['lr'], np.average(train_losses), \\\n",
    "                    loss.cpu().detach().tolist(), valid_ndcg, valid_mrr))\n",
    "        stats += [[np.average(train_losses), loss.cpu().detach().tolist()]]\n",
    "        del res, loss\n",
    "    del train_data, valid_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GraphNet Architecture\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GraphNetBlock(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, global_dim=0, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.global_dim = global_dim\n",
    "\n",
    "        # Edge update ^e\n",
    "        in_dim_e = edge_dim + 2*node_dim + global_dim\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim_e, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, edge_dim)\n",
    "        )\n",
    "\n",
    "        # Node update ^v\n",
    "        in_dim_v = node_dim + edge_dim + global_dim\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim_v, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, node_dim)\n",
    "        )\n",
    "\n",
    "        self.global_mlp = None\n",
    "\n",
    "    def forward(self, nodes, edges, senders, receivers, global_attr=None):\n",
    "        N, E = nodes.size(0), edges.size(0)\n",
    "\n",
    "        g_e = torch.zeros(E, 0, device=nodes.device)\n",
    "        g_v = torch.zeros(N, 0, device=nodes.device)\n",
    "\n",
    "        # ---- Edge update ----\n",
    "        #print(edges.shape, nodes[senders].shape, nodes[receivers].shape, g_e.shape)\n",
    "        edge_inputs = torch.cat([edges, nodes[senders], nodes[receivers], g_e], dim=-1)\n",
    "        edges_updated = self.edge_mlp(edge_inputs)\n",
    "\n",
    "        # ---- Node update ----\n",
    "        agg_messages = torch.zeros(N, edges_updated.size(-1), device=nodes.device)\n",
    "        agg_messages.index_add_(0, receivers, edges_updated)  # ^{ev} = sum\n",
    "        node_inputs = torch.cat([nodes, agg_messages, g_v], dim=-1)\n",
    "        nodes_updated = self.node_mlp(node_inputs)\n",
    "\n",
    "        return nodes_updated, edges_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac75597",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM-Type Architecture with rollout\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def reset_weights(m):\n",
    "    if hasattr(m, \"reset_parameters\"):\n",
    "        m.reset_parameters()\n",
    "\n",
    "class GraphTemporalModel(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.gn = GraphNetBlock(node_dim, edge_dim)\n",
    "        self.rnn = nn.LSTM(input_size=node_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.decoder = nn.Linear(hidden_dim, out_dim)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.gn.apply(reset_weights)\n",
    "        for name, param in self.rnn.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "        nn.init.xavier_uniform_(self.decoder.weight)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x_t, edge_features, senders, receivers, h=None, c=None):\n",
    "        \"\"\"\n",
    "        One-step prediction:\n",
    "          x_t : [B, N, F]  current node features\n",
    "          edge_features : [E, d_e]\n",
    "          senders, receivers : [E]\n",
    "          h, c : LSTM hidden + cell state\n",
    "        Returns:\n",
    "          x_next : [B, N, out_dim]\n",
    "          (h, c) : updated hidden states\n",
    "        \"\"\"\n",
    "        # Graph update\n",
    "        gn_out, _ = self.gn(x_t, edge_features, senders, receivers)  # [B, N, F]\n",
    "\n",
    "        # Reshape node features for RNN (flatten nodes as features)\n",
    "        rnn_in = gn_out.reshape(gn_out.size(0), 1, -1)  # [B, 1, N*F]\n",
    "\n",
    "        # RNN step\n",
    "        if h is not None and c is not None:\n",
    "            rnn_out, (h, c) = self.rnn(rnn_in, (h, c))\n",
    "        else:\n",
    "            rnn_out, (h, c) = self.rnn(rnn_in)\n",
    "\n",
    "        # Decode next node features\n",
    "        x_next = self.decoder(rnn_out)  # [B, 1, out_dim]\n",
    "        x_next = x_next.squeeze(1)      # [B, out_dim]\n",
    "\n",
    "        return x_next, (h, c)\n",
    "\n",
    "    def rollout(self, node_init, edge_features, senders, receivers, steps): ##TODO: time-dependent\n",
    "        \"\"\"\n",
    "        Autoregressive rollout for multiple steps.\n",
    "          node_init : [B, N, F]  initial node features\n",
    "          steps     : number of rollout steps\n",
    "        Returns:\n",
    "          preds : [B, steps, out_dim]\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        x_t = node_init\n",
    "        h, c = None, None\n",
    "\n",
    "        for _ in range(steps):\n",
    "            x_t, (h, c) = self.forward(x_t, edge_features, senders, receivers, h, c)\n",
    "            preds.append(x_t)\n",
    "\n",
    "        return torch.stack(preds, dim=1)  # [B, steps, out_dim]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7706c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM-Type Architecture without rollout\n",
    "\n",
    "def reset_weights(m):\n",
    "    if hasattr(m, \"reset_parameters\"):\n",
    "        m.reset_parameters()\n",
    "\n",
    "class GraphTemporalModelNoRollout(nn.Module):\n",
    "    def __init__(self, static_dim, state_dim, cond_dim, edge_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.static_dim = static_dim\n",
    "        self.state_dim = state_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        self.node_dim = static_dim + state_dim + cond_dim\n",
    "\n",
    "        self.gn = GraphNetBlock(self.node_dim, edge_dim)\n",
    "        self.rnn = nn.LSTM(input_size=self.node_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.decoder = nn.Linear(hidden_dim, self.state_dim)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.gn.apply(reset_weights)\n",
    "        for name, param in self.rnn.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "        nn.init.xavier_uniform_(self.decoder.weight)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "\n",
    "    def forward(self, state_t, cond_t, static_feat, edge_features, senders, receivers, hc=None):\n",
    "        # combine current prediction with known context\n",
    "        nodes = torch.cat([static_feat, state_t, cond_t], dim=-1)\n",
    "        \n",
    "        nodes, _ = self.gn(nodes, edge_features, senders, receivers)\n",
    "\n",
    "        #rnn_in = nodes.reshape(1, 1, -1) if nodes.dim() == 2 else nodes.reshape(nodes.size(0), 1, -1)\n",
    "        #print(self.state_dim,self.node_dim,nodes.shape)\n",
    "        #print(nodes.shape,edge_features.shape,senders.shape,receivers.shape)\n",
    "        rnn_out, hc = self.rnn(nodes, hc) if hc else self.rnn(nodes)\n",
    "        #rnn_out, hc = self.rnn(rnn_in, hc) if hc else self.rnn(rnn_in)\n",
    "        next_state = self.decoder(rnn_out.squeeze(1)).view_as(state_t)\n",
    "        return next_state, hc\n",
    "\n",
    "    def rollout(self, state_init, cond_seq, static_feat, edge_features, senders, receivers):\n",
    "        preds = []\n",
    "        state = state_init\n",
    "        hc = None\n",
    "        for cond_t in cond_seq:\n",
    "            state, hc = self.forward(state, cond_t, static_feat, edge_features, senders, receivers, hc)\n",
    "            preds.append(state)\n",
    "        return torch.stack(preds, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef47f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "simdata = torch.load('../torchfem_dataset/panel_plasticity/simulation_dump_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce22f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Dataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class GraphSeqDataset(Dataset):\n",
    "    def __init__(self, pt_path):\n",
    "        raw = torch.load(pt_path, map_location=\"cpu\")\n",
    "        # assume file is either a list[dict] or a dict of tensors\n",
    "        if isinstance(raw, dict) and all(torch.is_tensor(v) for v in raw.values()):\n",
    "            self.samples = [\n",
    "                {k: v[i] for k, v in raw.items()}\n",
    "                for i in range(next(iter(raw.values())).size(0))\n",
    "            ]\n",
    "        else:\n",
    "            self.samples = raw\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        return {\n",
    "            \"node_features\": sample[\"node_features\"].float(),\n",
    "            \"edge_features\": sample[\"edge_features\"].float(),\n",
    "            \"senders\": sample[\"senders\"].long(),\n",
    "            \"receivers\": sample[\"receivers\"].long(),\n",
    "            \"target\": sample.get(\"target\", sample[\"node_features\"]).float(),\n",
    "        }\n",
    "\n",
    "def graph_collate(batch):\n",
    "    # handles batch size >1; adjust if sequences have different lengths\n",
    "    out = {}\n",
    "    for key in batch[0]:\n",
    "        vals = [item[key] for item in batch]\n",
    "        if key in {\"senders\", \"receivers\"}:\n",
    "            out[key] = torch.stack(vals, dim=0)\n",
    "        else:\n",
    "            out[key] = torch.stack(vals, dim=0)\n",
    "    return out\n",
    "\n",
    "dataset = GraphSeqDataset(\"torchfem_dataset/panel_plasticity/panel_processed.pt\")\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=graph_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     59\u001b[39m receivers = receivers.squeeze(\u001b[32m0\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m#preds = rollout_from_dataset(gn, node_features_seq, edge_features,\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m#    senders, receivers)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m preds = \u001b[43mgn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msenders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreceivers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m preds = preds.permute(\u001b[32m1\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m2\u001b[39m)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# preds covers [1..T-1], align with ground truth\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m#print(preds.shape,target_seq.shape)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mGraphTemporalModel.rollout\u001b[39m\u001b[34m(self, node_init, edge_features, senders, receivers, steps)\u001b[39m\n\u001b[32m     68\u001b[39m h, c = \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     x_t, (h, c) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msenders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreceivers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     preds.append(x_t)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack(preds, dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mGraphTemporalModel.forward\u001b[39m\u001b[34m(self, x_t, edge_features, senders, receivers, h, c)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03mOne-step prediction:\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m  x_t : [B, N, F]  current node features\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m \u001b[33;03m  (h, c) : updated hidden states\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Graph update\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m gn_out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msenders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreceivers\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [B, N, F]\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Reshape node features for RNN (flatten nodes as features)\u001b[39;00m\n\u001b[32m     44\u001b[39m rnn_in = gn_out.reshape(gn_out.size(\u001b[32m0\u001b[39m), \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [B, 1, N*F]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mGraphNetBlock.forward\u001b[39m\u001b[34m(self, nodes, edges, senders, receivers, global_attr)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(edges.shape, nodes[senders].shape, nodes[receivers].shape, g_e.shape)\n\u001b[32m     37\u001b[39m edge_inputs = torch.cat([edges, nodes[senders], nodes[receivers], g_e], dim=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m edges_updated = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43medge_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# ---- Node update ----\u001b[39;00m\n\u001b[32m     41\u001b[39m agg_messages = torch.zeros(N, edges_updated.size(-\u001b[32m1\u001b[39m), device=nodes.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/activation.py:101\u001b[39m, in \u001b[36mReLU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/functional.py:1473\u001b[39m, in \u001b[36mrelu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   1471\u001b[39m     result = torch.relu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# GraphNet training loop - LSTM\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import time\n",
    "\n",
    "#dataset = torch.load('torchfem_dataset/panel_plasticity/simulation_.pt')\n",
    "#loader = DataLoader(dataset, batch_size=1, shuffle=True)  # batch size 1 for rollout\n",
    "device = 'cuda:0'\n",
    "loader = DataLoader(dataset, batch_size=1, collate_fn=graph_collate)\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "node_dim = sample[\"node_features\"].shape[-1]\n",
    "edge_dim = sample[\"edge_features\"].shape[-1]\n",
    "out_dim = node_dim                # or whatever target width you predict\n",
    "\n",
    "gn = GraphTemporalModel(\n",
    "    node_dim=node_dim,\n",
    "    edge_dim=edge_dim,\n",
    "    hidden_dim=128,\n",
    "    out_dim=out_dim,\n",
    ").to(device)\n",
    "gn.apply(reset_weights)\n",
    "\n",
    "optimizer = optim.AdamW(gn.parameters(), lr=5e-2)\n",
    "loss_fn = nn.SmoothL1Loss() ##TODO: physics-informed loss\n",
    "epochs = 10\n",
    "losses = []\n",
    "\n",
    "def rollout_from_dataset(gn, node_features_seq, edge_features, \n",
    "                         senders, receivers):\n",
    "    \"\"\"\n",
    "    Unroll the GN across the sequence length T.\n",
    "    \"\"\"\n",
    "    T, N, F = node_features_seq.shape[0], node_features_seq.shape[1], node_features_seq.shape[1:]\n",
    "    preds = []\n",
    "\n",
    "    nodes_t = node_features_seq[0]  # initial state\n",
    "    for t in range(T-1):\n",
    "        # forward pass\n",
    "        #print(nodes_t.shape,edge_features.shape,senders.shape,receivers.shape)\n",
    "        nodes_t, _= gn(nodes_t, edge_features, senders, receivers) #nodes_t,_,_\n",
    "        preds.append(nodes_t)   # keep entire state prediction\n",
    "    return torch.stack(preds, dim=0)  # [T-1, N, F]\n",
    "\n",
    "max_batches = 5\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        if batch_idx >= max_batches:\n",
    "            break\n",
    "        node_features_seq, edge_features, senders, receivers, target_seq = batch['node_features'],batch['edge_features'],batch['senders'],batch['receivers'],batch['node_features']\n",
    "        \n",
    "        node_features_seq = node_features_seq.squeeze(0)      # [T,N,F]\n",
    "        steps = node_features_seq.shape[0]\n",
    "        edge_features = edge_features.squeeze(0)              # [E,D]\n",
    "        #global_features_seq = global_features_seq.squeeze(0)  # [T,G]\n",
    "        target_seq = target_seq.squeeze(0)                    # [T,N,out_dim]\n",
    "        senders = senders.squeeze(0)\n",
    "        receivers = receivers.squeeze(0)\n",
    "        #preds = rollout_from_dataset(gn, node_features_seq, edge_features,\n",
    "        #    senders, receivers)\n",
    "\n",
    "        preds = gn.rollout(node_features_seq[0], edge_features, senders, receivers, steps)\n",
    "        preds = preds.permute(1,0,2)\n",
    "        # preds covers [1..T-1], align with ground truth\n",
    "        #print(preds.shape,target_seq.shape)\n",
    "        loss = loss_fn(preds[1:], target_seq[1:])  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        #print(total_loss)\n",
    "    losses.append(total_loss)\n",
    "\n",
    "    #if epoch % 20 == 0:\n",
    "    print(f\"Epoch {epoch}, Loss={total_loss/len(loader):.2f}\")\n",
    "torch.save({'model':gn.state_dict(),'optimizer':optimizer.state_dict()},'torchfem_dataset/weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c45f275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss=0.8523\n",
      "Epoch 1, Loss=0.7015\n",
      "Epoch 2, Loss=0.6442\n",
      "Epoch 3, Loss=0.6116\n",
      "Epoch 4, Loss=0.5959\n",
      "Epoch 5, Loss=0.6105\n",
      "Epoch 6, Loss=0.6002\n",
      "Epoch 7, Loss=0.5837\n",
      "Epoch 8, Loss=0.5658\n",
      "Epoch 9, Loss=0.5793\n",
      "Epoch 10, Loss=0.5763\n",
      "Epoch 11, Loss=0.5647\n",
      "Epoch 12, Loss=0.5635\n",
      "Epoch 13, Loss=0.5601\n",
      "Epoch 14, Loss=0.5546\n",
      "Epoch 15, Loss=0.5596\n",
      "Epoch 16, Loss=0.5559\n",
      "Epoch 17, Loss=0.5433\n",
      "Epoch 18, Loss=0.5412\n",
      "Epoch 19, Loss=0.5465\n",
      "Epoch 20, Loss=0.5280\n",
      "Epoch 21, Loss=0.5311\n",
      "Epoch 22, Loss=0.5313\n",
      "Epoch 23, Loss=0.5687\n",
      "Epoch 24, Loss=0.5426\n",
      "Epoch 25, Loss=0.5404\n",
      "Epoch 26, Loss=0.5236\n",
      "Epoch 27, Loss=0.5113\n",
      "Epoch 28, Loss=0.5009\n",
      "Epoch 29, Loss=0.5004\n",
      "Epoch 30, Loss=0.4960\n",
      "Epoch 31, Loss=0.4959\n",
      "Epoch 32, Loss=0.4878\n",
      "Epoch 33, Loss=0.4831\n",
      "Epoch 34, Loss=0.4783\n",
      "Epoch 35, Loss=0.4780\n",
      "Epoch 36, Loss=0.4779\n",
      "Epoch 37, Loss=0.4723\n",
      "Epoch 38, Loss=0.4774\n",
      "Epoch 39, Loss=0.4753\n",
      "Epoch 40, Loss=0.4814\n",
      "Epoch 41, Loss=0.4810\n",
      "Epoch 42, Loss=0.4757\n",
      "Epoch 43, Loss=0.4698\n",
      "Epoch 44, Loss=0.4631\n",
      "Epoch 45, Loss=0.4556\n",
      "Epoch 46, Loss=0.4564\n",
      "Epoch 47, Loss=0.4544\n",
      "Epoch 48, Loss=0.4623\n",
      "Epoch 49, Loss=0.4553\n"
     ]
    }
   ],
   "source": [
    "# GraphNet training loop - LSTM no rollout\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import time\n",
    "\n",
    "#dataset = torch.load('torchfem_dataset/panel_plasticity/simulation_.pt')\n",
    "#loader = DataLoader(dataset, batch_size=1, shuffle=True)  # batch size 1 for rollout\n",
    "device = 'cpu'\n",
    "dataset = GraphSeqDataset(\"torchfem_dataset/panel_plasticity/panel_processed.pt\")\n",
    "loader = DataLoader(dataset, batch_size=1, collate_fn=graph_collate)\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "node_features_seq, edge_features, senders, receivers, target_seq = sample['node_features'],sample['edge_features'],sample['senders'],sample['receivers'],sample['target']\n",
    "\n",
    "\n",
    "node_features_seq = node_features_seq.squeeze(0)        # [T, N, F]\n",
    "time_diff = node_features_seq[1:] - node_features_seq[:-1]\n",
    "dynamic_mask = time_diff.abs().max(dim=0).values > 1e-6 # [N, F]\n",
    "dynamic_mask = dynamic_mask.any(dim=0)                  # [F]\n",
    "static_idx = (~dynamic_mask).nonzero(as_tuple=True)[0]\n",
    "dynamic_idx = dynamic_mask.nonzero(as_tuple=True)[0]\n",
    "static_feat = node_features_seq[0, :, static_idx]                     # [N, static_dim]\n",
    "dynamic_seq = node_features_seq[:, :, dynamic_idx]                    # [T, N, dynamic_dim]\n",
    "state_dim = dynamic_seq.size(-1) // 2\n",
    "state_seq = dynamic_seq[:, :, :state_dim]\n",
    "cond_seq = dynamic_seq[:, :, state_dim:]\n",
    "\n",
    "gn = GraphTemporalModelNoRollout(\n",
    "            static_dim=static_feat.size(-1),\n",
    "            state_dim=state_dim,\n",
    "            cond_dim=cond_seq.size(-1),\n",
    "            edge_dim=edge_features.size(-1),\n",
    "            hidden_dim=128,\n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(gn.parameters(), lr=1e-4)\n",
    "loss_fn = nn.SmoothL1Loss() ##TODO: physics-informed loss\n",
    "epochs = 50\n",
    "losses = []\n",
    "\n",
    "\n",
    "\n",
    "max_batches = 20\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        if batch_idx >= max_batches:\n",
    "            break\n",
    "        node_features_seq, edge_features, senders, receivers, target_seq = batch['node_features'],batch['edge_features'],batch['senders'],batch['receivers'],batch['node_features']\n",
    "\n",
    "        target_seq = target_seq.squeeze(0)                    # [T,N,out_dim]\n",
    "        senders = senders.squeeze(0)\n",
    "        receivers = receivers.squeeze(0)\n",
    "\n",
    "        node_features_seq = node_features_seq.squeeze(0)        # [T, N, F]\n",
    "        time_diff = node_features_seq[1:] - node_features_seq[:-1]\n",
    "        dynamic_mask = time_diff.abs().max(dim=0).values > 1e-6 # [N, F]\n",
    "        dynamic_mask = dynamic_mask.any(dim=0)                  # [F]\n",
    "        static_idx = (~dynamic_mask).nonzero(as_tuple=True)[0]\n",
    "        dynamic_idx = dynamic_mask.nonzero(as_tuple=True)[0]\n",
    "\n",
    "        static_feat = node_features_seq[0, :, static_idx]                     # [N, static_dim]\n",
    "        dynamic_seq = node_features_seq[:, :, dynamic_idx]                    # [T, N, dynamic_dim]\n",
    "        state_dim = dynamic_seq.size(-1) // 2\n",
    "        state_seq = dynamic_seq[:, :, :state_dim]\n",
    "        cond_seq = dynamic_seq[:, :, state_dim:]\n",
    "\n",
    "        state_init = state_seq[0]\n",
    "        known_cond = cond_seq[:-1]          # length T-1 aligns with transitions\n",
    "        target_states = state_seq[1:]       # ground truth next states\n",
    "        \n",
    "        #print(state_init.shape,known_cond.shape,static_feat.shape,edge_features[0].shape,senders.shape,receivers.shape)\n",
    "        preds = gn.rollout(state_init, known_cond, static_feat, edge_features[0], senders, receivers)\n",
    "        loss = loss_fn(preds, target_states)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        #print(total_loss)\n",
    "    losses.append(total_loss)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss={total_loss/len(loader):.4f}\")\n",
    "torch.save({'model':gn.state_dict(),'optimizer':optimizer.state_dict()},'torchfem_dataset/weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3ce0d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('Losses')\n",
    "plt.ylabel('Smooth L1')\n",
    "plt.plot(losses,'k')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xlim(0,len(losses)-1)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('torchfem_dataset/losses.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DiffPool\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "def build_dense_adj(senders: torch.Tensor, receivers: torch.Tensor, num_nodes: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Builds a symmetric adjacency matrix for a single graph.\n",
    "    \"\"\"\n",
    "    adj = torch.zeros(num_nodes, num_nodes, device=senders.device)\n",
    "    adj[senders, receivers] = 1.0\n",
    "    adj[receivers, senders] = 1.0\n",
    "    adj.fill_diagonal_(1.0)\n",
    "    return adj\n",
    "\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Lightweight message-passing block used both for embeddings and assignments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, node_dim: int, edge_dim: int, hidden_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        nodes: torch.Tensor,\n",
    "        edge_attr: torch.Tensor,\n",
    "        senders: torch.Tensor,\n",
    "        receivers: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        msg_input = torch.cat([nodes[senders], edge_attr], dim=-1)\n",
    "        messages = self.edge_mlp(msg_input)\n",
    "\n",
    "        agg = torch.zeros(nodes.size(0), messages.size(-1), device=nodes.device)\n",
    "        agg.index_add_(0, receivers, messages)\n",
    "\n",
    "        node_input = torch.cat([nodes, agg], dim=-1)\n",
    "        return self.node_mlp(node_input)\n",
    "\n",
    "\n",
    "class DiffPoolLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Single DiffPool layer: learns cluster assignments and pooled embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        edge_dim: int,\n",
    "        hidden_dim: int,\n",
    "        assign_dim: int,\n",
    "        clusters: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_gnn = GraphConv(input_dim, edge_dim, hidden_dim, hidden_dim)\n",
    "        self.assign_gnn = GraphConv(input_dim, edge_dim, hidden_dim, clusters)\n",
    "        self.assign_proj = nn.Linear(clusters, assign_dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        nodes: torch.Tensor,\n",
    "        adj: torch.Tensor,\n",
    "        edge_attr: torch.Tensor,\n",
    "        senders: torch.Tensor,\n",
    "        receivers: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        z = self.embed_gnn(nodes, edge_attr, senders, receivers)\n",
    "        s_logits = self.assign_gnn(nodes, edge_attr, senders, receivers)\n",
    "        s = torch.softmax(s_logits, dim=-1)\n",
    "\n",
    "        x_pooled = torch.matmul(s.transpose(0, 1), z)\n",
    "        adj_pooled = torch.matmul(torch.matmul(s.transpose(0, 1), adj), s)\n",
    "\n",
    "        info = {\n",
    "            \"assign_logits\": s_logits,\n",
    "            \"assign_soft\": s,\n",
    "            \"node_embed\": z,\n",
    "        }\n",
    "        return x_pooled, adj_pooled, info\n",
    "\n",
    "\n",
    "class GraphTemporalDiffPool(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal forecaster with DiffPool for graph-level compression.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_dim: int,\n",
    "        edge_dim: int,\n",
    "        hidden_dim: int,\n",
    "        out_dim: int,\n",
    "        clusters: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pre_gnn = GraphConv(node_dim, edge_dim, hidden_dim, hidden_dim)\n",
    "        self.pool = DiffPoolLayer(hidden_dim, edge_dim, hidden_dim, hidden_dim, clusters)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=hidden_dim * clusters,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_t: torch.Tensor,\n",
    "        edge_attr: torch.Tensor,\n",
    "        senders: torch.Tensor,\n",
    "        receivers: torch.Tensor,\n",
    "        state: Tuple[torch.Tensor, torch.Tensor] | None = None,\n",
    "    ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor], Dict[str, torch.Tensor]]:\n",
    "        pooled_repr = []\n",
    "        pool_info: Dict[str, torch.Tensor] = {}\n",
    "\n",
    "        for b in range(x_t.size(0)):\n",
    "            nodes = self.pre_gnn(x_t[b], edge_attr[b], senders[b], receivers[b])\n",
    "\n",
    "            adj = build_dense_adj(senders[b], receivers[b], nodes.size(0))\n",
    "            x_pool, _, info = self.pool(\n",
    "                nodes,\n",
    "                adj,\n",
    "                edge_attr[b],\n",
    "                senders[b],\n",
    "                receivers[b],\n",
    "            )\n",
    "\n",
    "            pooled_repr.append(x_pool.reshape(-1))\n",
    "            if b == 0:\n",
    "                pool_info = {k: v.detach() for k, v in info.items()}\n",
    "\n",
    "        rnn_in = torch.stack(pooled_repr, dim=0).unsqueeze(1)\n",
    "\n",
    "        if state is None:\n",
    "            rnn_out, state = self.rnn(rnn_in)\n",
    "        else:\n",
    "            rnn_out, state = self.rnn(rnn_in, state)\n",
    "\n",
    "        preds = self.decoder(rnn_out.squeeze(1))\n",
    "        return preds, state, pool_info\n",
    "\n",
    "    def rollout(\n",
    "        self,\n",
    "        node_init: torch.Tensor,\n",
    "        edge_attr: torch.Tensor,\n",
    "        senders: torch.Tensor,\n",
    "        receivers: torch.Tensor,\n",
    "        steps: int,\n",
    "    ) -> torch.Tensor:\n",
    "        preds = []\n",
    "        x_t = node_init\n",
    "        state = None\n",
    "\n",
    "        for _ in range(steps):\n",
    "            x_t, state, _ = self.forward(x_t, edge_attr, senders, receivers, state)\n",
    "            preds.append(x_t)\n",
    "\n",
    "        return torch.stack(preds, dim=1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    batch_size, num_nodes, node_dim = 1, 6, 4\n",
    "    edge_dim, clusters = 3, 3\n",
    "    out_dim, rollout_steps = node_dim, 5\n",
    "\n",
    "    node_features = torch.randn(batch_size, num_nodes, node_dim)\n",
    "\n",
    "    edge_list = []\n",
    "    for i in range(num_nodes):\n",
    "        j = (i + 1) % num_nodes\n",
    "        edge_list.append((i, j))\n",
    "        edge_list.append((j, i))\n",
    "\n",
    "    senders = torch.tensor([s for s, _ in edge_list]).unsqueeze(0)\n",
    "    receivers = torch.tensor([r for _, r in edge_list]).unsqueeze(0)\n",
    "    edge_features = torch.randn(batch_size, len(edge_list), edge_dim)\n",
    "\n",
    "    model = GraphTemporalDiffPool(\n",
    "        node_dim=node_dim,\n",
    "        edge_dim=edge_dim,\n",
    "        hidden_dim=32,\n",
    "        out_dim=out_dim,\n",
    "        clusters=clusters,\n",
    "    )\n",
    "\n",
    "    out, _, info = model(node_features, edge_features, senders, receivers)\n",
    "    print(\"Single step output:\", out.shape)\n",
    "    print(\"Assignment matrix example:\", info[\"assign_soft\"].shape)\n",
    "\n",
    "    preds = model.rollout(\n",
    "        node_features,\n",
    "        edge_features,\n",
    "        senders,\n",
    "        receivers,\n",
    "        steps=rollout_steps,\n",
    "    )\n",
    "    print(\"Rollout output:\", preds.shape)\n",
    "\n",
    "    # Expand: swap synthetic data with the real FEM dataset loader, add batching >1,\n",
    "    #         and plug the pooled embeddings into your training loop with losses/metrics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
