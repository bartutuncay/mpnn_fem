{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c03663",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine datasets -- NOT IN USE\n",
    "import glob\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def merge_pt_files(pt_paths):\n",
    "    merged = {}\n",
    "    for path in pt_paths:\n",
    "        data = torch.load(path, map_location='cpu')\n",
    "        if not merged:\n",
    "            merged = {k: [v] for k, v in data.items()}\n",
    "            continue\n",
    "        if data.keys() != merged.keys():\n",
    "            print(data.keys(),merged.keys())\n",
    "            raise ValueError(f\"Key mismatch in {path}\")\n",
    "        for k, v in data.items():\n",
    "            merged[k].append(v)\n",
    "    for k, tensors in merged.items():\n",
    "        try:\n",
    "            merged[k] = torch.cat(tensors, dim=0)\n",
    "        except RuntimeError:\n",
    "            merged[k] = tensors \n",
    "    return merged\n",
    "\n",
    "pt_files = glob.glob(\"torchfem_dataset/panel_plasticity/*.pt\")\n",
    "combined = merge_pt_files(pt_files)\n",
    "torch.save(combined, \"torchfem_dataset/panel_plasticity/combined.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e720bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aluminum\n",
      "steel\n",
      "aluminum\n",
      "steel\n",
      "aluminum\n",
      "aluminum\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "aluminum\n",
      "aluminum\n",
      "steel\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "CFRP\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "steel\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "aluminum\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "aluminum\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "aluminum\n",
      "aluminum\n",
      "aluminum\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "steel\n",
      "CFRP\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "aluminum\n",
      "aluminum\n",
      "steel\n",
      "steel\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "CFRP\n",
      "aluminum\n",
      "CFRP\n",
      "steel\n",
      "CFRP\n",
      "CFRP\n",
      "Wrote 124 samples to ../torchfem_dataset/panel_processed.pt\n"
     ]
    }
   ],
   "source": [
    "## Modify Dataset with Material Labels -- NOT IN USE AS OF NOV 8\n",
    "import torch\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "mat_df = pd.read_csv(\"../torchfem_dataset/tube/materials.csv\")\n",
    "\n",
    "files = glob.glob('../torchfem_dataset/panel_plasticity/simulation_dump*.pt')\n",
    "\n",
    "material_map = {'concrete':0,'steel':1,'aluminum':2,'CFRP':3}\n",
    "\n",
    "def stiffness_to_edges(K, num_nodes, dof_per_node=3):\n",
    "    K = K.coalesce()\n",
    "    dof_rows, dof_cols = K.indices()\n",
    "    node_rows = torch.div(dof_rows, dof_per_node, rounding_mode='floor')\n",
    "    node_cols = torch.div(dof_cols, dof_per_node, rounding_mode='floor')\n",
    "    block_ids = node_rows * num_nodes + node_cols\n",
    "\n",
    "    uniq_blocks, inverse = torch.unique(block_ids, return_inverse=True)\n",
    "    local_row = dof_rows % dof_per_node\n",
    "    local_col = dof_cols % dof_per_node\n",
    "    flat_offsets = inverse * (dof_per_node * dof_per_node) + local_row * dof_per_node + local_col\n",
    "\n",
    "    edge_attr_flat = torch.zeros(\n",
    "        uniq_blocks.numel() * dof_per_node * dof_per_node,\n",
    "        dtype=K.values().dtype,\n",
    "        device=K.values().device,\n",
    "    )\n",
    "    edge_attr_flat.scatter_add_(0, flat_offsets, K.values())\n",
    "    edge_attr = edge_attr_flat.view(uniq_blocks.numel(), dof_per_node, dof_per_node)\n",
    "\n",
    "    senders = torch.div(uniq_blocks, num_nodes, rounding_mode='floor')\n",
    "    receivers = uniq_blocks % num_nodes\n",
    "    return senders.long(), receivers.long(), edge_attr.reshape(uniq_blocks.numel(), -1).float()\n",
    "\n",
    "def build_graph_sample(material,sim, t_stride=1):\n",
    "    nodes = sim[\"nodes\"].float()\n",
    "    u_hist = sim[\"u_history\"][::t_stride].float()\n",
    "    f_hist = sim[\"forces\"][::t_stride].float()\n",
    "    dirichlet = sim.get(\"dirichlet_disp\", torch.zeros_like(nodes)).float()\n",
    "    constraints = sim.get(\"boundary\", sim.get(\"constraints\", torch.zeros_like(nodes, dtype=torch.bool))).float()\n",
    "\n",
    "    static = torch.cat([nodes, dirichlet, constraints], dim=-1)\n",
    "    static = static.unsqueeze(0).expand(u_hist.size(0), -1, -1)\n",
    "    dynamic = torch.cat([u_hist, f_hist], dim=-1)\n",
    "    node_features = torch.cat([static, dynamic], dim=-1)\n",
    "\n",
    "    senders, receivers, edge_features = stiffness_to_edges(\n",
    "        sim[\"stiffness\"],\n",
    "        num_nodes=nodes.size(0),\n",
    "        dof_per_node=nodes.size(1),\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"node_features\": node_features,\n",
    "        \"edge_features\": edge_features,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"target\": u_hist,\n",
    "    }\n",
    "\n",
    "def preprocess_panel_dataset(src_dir=\"../torchfem_dataset/panel_plasticity\",\n",
    "                             dst_path=\"../torchfem_dataset/panel_processed.pt\",\n",
    "                             t_stride=1):\n",
    "    src_dir = Path(src_dir)\n",
    "    samples = []\n",
    "    for pt_file in sorted(src_dir.glob(\"simulation_dump*.pt\")):\n",
    "        idx = int(str(pt_file).split('simulation_dump_')[1].split('.pt')[0])\n",
    "        material = mat_df[mat_df['0']==idx]\n",
    "        mat = material['1'].item()\n",
    "        sim = torch.load(pt_file, map_location=\"cpu\")\n",
    "        samples.append(build_graph_sample(mat,sim, t_stride=t_stride))\n",
    "    Path(dst_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    #torch.save(samples, dst_path)\n",
    "    print(f\"Wrote {len(samples)} samples to {dst_path}\")\n",
    "\n",
    "# Run once to create the processed file\n",
    "preprocess_panel_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6e759",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     93\u001b[39m         samples.append(data)\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m samples\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m dataset = \u001b[43mbuild_hetero_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m     \u001b[49m\u001b[43msrc_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../torchfem_dataset/tube\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m     \u001b[49m\u001b[43mmaterials_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../torchfem_dataset/tube/materials.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m     \u001b[49m\u001b[43mt_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# torch.save(dataset, \"../torchfem_dataset/panel_plasticity/hetero_panel.pt\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 92\u001b[39m, in \u001b[36mbuild_hetero_dataset\u001b[39m\u001b[34m(src_dir, materials_csv, t_stride)\u001b[39m\n\u001b[32m     90\u001b[39m     sim[\u001b[33m\"\u001b[39m\u001b[33mu_history\u001b[39m\u001b[33m\"\u001b[39m] = sim[\u001b[33m\"\u001b[39m\u001b[33mu_history\u001b[39m\u001b[33m\"\u001b[39m][::t_stride]\n\u001b[32m     91\u001b[39m     sim[\u001b[33m\"\u001b[39m\u001b[33mforces\u001b[39m\u001b[33m\"\u001b[39m] = sim[\u001b[33m\"\u001b[39m\u001b[33mforces\u001b[39m\u001b[33m\"\u001b[39m][::t_stride]\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     data = \u001b[43mbuild_hetero_graph_for_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaterial_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaterial_vocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     samples.append(data)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m samples\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mbuild_hetero_graph_for_sim\u001b[39m\u001b[34m(sim, material_label, material_vocab, edge_mode)\u001b[39m\n\u001b[32m     62\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mapplies_to_rev\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmat\u001b[39m\u001b[33m\"\u001b[39m].edge_index = mat_to_nodes.flip(\u001b[32m0\u001b[39m)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# optional node adjacency edges\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m ei = \u001b[43mstiffness_to_node_adj_edge_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstiffness\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdof_per_node\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33madjacent\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m\"\u001b[39m].edge_index = ei\n\u001b[32m     67\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33madjacent_rev\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m\"\u001b[39m].edge_index = ei.flip(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mstiffness_to_node_adj_edge_index\u001b[39m\u001b[34m(K, num_nodes, dof_per_node)\u001b[39m\n\u001b[32m     27\u001b[39m mask = ei[\u001b[32m0\u001b[39m] != ei[\u001b[32m1\u001b[39m]\n\u001b[32m     28\u001b[39m ei = ei[:, mask]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m ei = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ei\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bm_tu\\Desktop\\gnn\\gnn_312\\Lib\\site-packages\\torch\\_jit_internal.py:622\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bm_tu\\Desktop\\gnn\\gnn_312\\Lib\\site-packages\\torch\\_jit_internal.py:622\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bm_tu\\Desktop\\gnn\\gnn_312\\Lib\\site-packages\\torch\\functional.py:1102\u001b[39m, in \u001b[36m_return_output\u001b[39m\u001b[34m(input, sorted, return_inverse, return_counts, dim)\u001b[39m\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[32m   1100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[32m-> \u001b[39m\u001b[32m1102\u001b[39m output, _, _ = \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bm_tu\\Desktop\\gnn\\gnn_312\\Lib\\site-packages\\torch\\functional.py:987\u001b[39m, in \u001b[36m_unique_impl\u001b[39m\u001b[34m(input, sorted, return_inverse, return_counts, dim)\u001b[39m\n\u001b[32m    976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    977\u001b[39m         unique,\n\u001b[32m    978\u001b[39m         (\u001b[38;5;28minput\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    983\u001b[39m         dim=dim,\n\u001b[32m    984\u001b[39m     )\n\u001b[32m    986\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m987\u001b[39m     output, inverse_indices, counts = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique_dim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    995\u001b[39m     output, inverse_indices, counts = torch._unique2(\n\u001b[32m    996\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    997\u001b[39m         \u001b[38;5;28msorted\u001b[39m=\u001b[38;5;28msorted\u001b[39m,\n\u001b[32m    998\u001b[39m         return_inverse=return_inverse,\n\u001b[32m    999\u001b[39m         return_counts=return_counts,\n\u001b[32m   1000\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "## PyG HeteroData -- NOT IN USE\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import pandas as pd\n",
    "\n",
    "def load_material_vocab(materials_csv: str) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    df = pd.read_csv(materials_csv, header=None, names=[\"sim_id\", \"label\"])\n",
    "    labels = sorted(df[\"label\"].astype(str).unique().tolist())\n",
    "    vocab = {lbl: i for i, lbl in enumerate(labels)}\n",
    "    sim_to_label = {int(r.sim_id): str(r.label) for _, r in df.iterrows()}\n",
    "    return vocab, sim_to_label\n",
    "\n",
    "def one_hot(label: str, vocab: Dict[str, int], device=None, dtype=torch.float) -> torch.Tensor:\n",
    "    vec = torch.zeros(len(vocab), dtype=dtype, device=device)\n",
    "    vec[vocab[label]] = 1.0\n",
    "    return vec\n",
    "\n",
    "def stiffness_to_node_adj_edge_index(K: torch.Tensor, num_nodes: int, dof_per_node: int = 3) -> torch.Tensor:\n",
    "    K = K.coalesce()\n",
    "    dof_rows, dof_cols = K.indices()\n",
    "    node_rows = torch.div(dof_rows, dof_per_node, rounding_mode=\"floor\")\n",
    "    node_cols = torch.div(dof_cols, dof_per_node, rounding_mode=\"floor\")\n",
    "    ei = torch.stack([node_rows.long(), node_cols.long()], dim=0)\n",
    "    mask = ei[0] != ei[1]\n",
    "    ei = ei[:, mask]\n",
    "    ei = torch.unique(ei, dim=1)\n",
    "    return ei\n",
    "\n",
    "def build_hetero_graph_for_sim(\n",
    "    sim: Dict[str, torch.Tensor],\n",
    "    material_label: str,\n",
    "    material_vocab: Dict[str, int],\n",
    "    edge_mode: str = \"from_K\"  # \"from_K\" or \"knn\" or \"none\"\n",
    "    ) -> HeteroData:\n",
    "    nodes = sim[\"nodes\"].float()        # [N, 3]\n",
    "    u_hist = sim[\"u_history\"].float()   # [T, N, 3]\n",
    "    f_hist = sim[\"forces\"].float()      # [T, N, 3]\n",
    "    dirichlet = sim.get(\"dirichlet_disp\", torch.zeros_like(nodes)).float()  # [N, 3]\n",
    "    constraints = sim.get(\"boundary\", sim.get(\"constraints\", torch.zeros_like(nodes, dtype=torch.bool))).float()\n",
    "\n",
    "    data = HeteroData()\n",
    "\n",
    "    # node-type features\n",
    "    data[\"node\"].pos = nodes                              # [N, d]\n",
    "    data[\"node\"].dirichlet = dirichlet                    # [N, dof]\n",
    "    data[\"node\"].bc_mask = constraints                    # [N, dof]\n",
    "    data[\"node\"].u_hist = u_hist                          # [T, N, dof]\n",
    "    data[\"node\"].f_hist = f_hist                          # [T, N, dof]\n",
    "\n",
    "    # material-type node (one per sample)\n",
    "    mat_oh = one_hot(material_label, material_vocab, device=nodes.device)\n",
    "    data[\"mat\"].x = mat_oh.unsqueeze(0)                   # [1, C]\n",
    "    data[\"mat\"].index = torch.tensor([material_vocab[material_label]], dtype=torch.long)\n",
    "\n",
    "    # incidence from material to all nodes\n",
    "    N = nodes.size(0)\n",
    "    mat_to_nodes = torch.stack([torch.zeros(N, dtype=torch.long), torch.arange(N, dtype=torch.long)], dim=0)  # [2, N]\n",
    "    data[\"mat\", \"applies_to\", \"node\"].edge_index = mat_to_nodes\n",
    "    data[\"node\", \"applies_to_rev\", \"mat\"].edge_index = mat_to_nodes.flip(0)\n",
    "\n",
    "    # optional node adjacency edges\n",
    "    ei = stiffness_to_node_adj_edge_index(sim[\"stiffness\"], num_nodes=N, dof_per_node=nodes.size(1))\n",
    "    data[\"node\", \"adjacent\", \"node\"].edge_index = ei\n",
    "    data[\"node\", \"adjacent_rev\", \"node\"].edge_index = ei.flip(0)\n",
    "\n",
    "    # optional edge features (e.g., relative displacement or unit scalar)\n",
    "    if (\"node\", \"adjacent\", \"node\") in data.edge_types:\n",
    "        ei = data[\"node\", \"adjacent\", \"node\"].edge_index\n",
    "        data[\"node\", \"adjacent\", \"node\"].edge_attr = (nodes[ei[1]] - nodes[ei[0]]).float()  # [E, d]\n",
    "\n",
    "    # training targets\n",
    "    data[\"node\"].y = u_hist  # [T, N, dof]\n",
    "    #data[\"node\"].y = u_hist  # [T, N, dof] #TODO: add stress history\n",
    "\n",
    "    return data\n",
    "\n",
    "def build_hetero_dataset(\n",
    "    src_dir: str = \"../torchfem_dataset/panel_plasticity\",\n",
    "    materials_csv: str = \"../torchfem_dataset/panel_plasticity/materials.csv\",\n",
    "    t_stride: int = 1,\n",
    "    ) -> List[HeteroData]:\n",
    "    vocab, sim_to_label = load_material_vocab(materials_csv)\n",
    "    samples: List[HeteroData] = []\n",
    "    for pt_file in sorted(Path(src_dir).glob(\"simulation_dump*.pt\")):\n",
    "        idx = int(str(pt_file).split(\"simulation_dump_\")[1].split(\".pt\")[0])\n",
    "        label = sim_to_label[idx]\n",
    "        sim = torch.load(pt_file, map_location=\"cpu\")\n",
    "        sim[\"u_history\"] = sim[\"u_history\"][::t_stride]\n",
    "        sim[\"forces\"] = sim[\"forces\"][::t_stride]\n",
    "        data = build_hetero_graph_for_sim(sim, material_label=label, material_vocab=vocab)\n",
    "        samples.append(data)\n",
    "    return samples\n",
    "\n",
    "dataset = build_hetero_dataset(\n",
    "     src_dir=\"../torchfem_dataset/tube\",\n",
    "     materials_csv=\"../torchfem_dataset/tube/materials.csv\",\n",
    "     t_stride=1)\n",
    "# torch.save(dataset, \"../torchfem_dataset/panel_plasticity/hetero_panel.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9cc12ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6466, 3])\n",
      "torch.Size([200, 3120, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#data = torch.load('../base/torchfem_dataset/processed/simulation_dump_3.pt')\n",
    "data = torch.load('../torchfem_dataset/panel_plasticity_2/simulation_dump_3.pt',weights_only=False)\n",
    "print(data['nodes'].shape)\n",
    "print(data['stress_history'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269910fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_10.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_100.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_101.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_102.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_103.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_104.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_105.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_106.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_107.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_108.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_11.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_110.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_111.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_112.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_113.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_114.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_115.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_117.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_118.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_119.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_12.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_120.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_121.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_122.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_123.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_124.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_125.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_126.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_127.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_128.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_129.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_13.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_130.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_133.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_134.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_135.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_136.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_137.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_138.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_139.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_14.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_140.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_141.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_142.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_143.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_144.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_145.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_147.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_148.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_149.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_15.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_150.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_17.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_18.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_2.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_20.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_22.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_24.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_25.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_27.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_28.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_3.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_30.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_31.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_32.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_33.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_37.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_38.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_39.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_4.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_40.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_41.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_42.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_43.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_44.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_46.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_47.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_48.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_49.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_5.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_50.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_51.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_52.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_53.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_54.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_56.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_58.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_59.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_6.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_60.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_62.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_63.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_64.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_65.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_66.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_67.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_68.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_69.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_7.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_70.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_71.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_72.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_73.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_74.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_76.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_79.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_8.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_80.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_81.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_83.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_84.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_85.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_86.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_87.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_88.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_9.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_90.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_91.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_92.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_93.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_95.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_96.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_97.pt\n",
      "../base/torchfem_dataset/panel_euler/panel_plasticity/simulation_dump_98.pt\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "## PyG Graph with Mesh & Element Nodes - additional material encoding\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import pandas as pd\n",
    "\n",
    "# Material encoding (1-h)\n",
    "def load_material_vocab(materials_csv: str) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    # CSV: idx,label\n",
    "    df = pd.read_csv(materials_csv, header=None, names=[\"sim_id\", \"label\"])\n",
    "    #labels = sorted(df[\"label\"].astype(str).unique().tolist())\n",
    "    labels = ['concrete','steel','aluminum','CFRP'] #0,1,2,3 fixed material labels for now\n",
    "    vocab = {lbl: i for i, lbl in enumerate(labels)}\n",
    "    sim_to_label = {int(r.sim_id): str(r.label) for _, r in df.iterrows()}\n",
    "    return vocab, sim_to_label\n",
    "\n",
    "def one_hot(label: str, vocab: Dict[str, int], device=None, dtype=torch.float) -> torch.Tensor:\n",
    "    vec = torch.zeros(len(vocab), dtype=dtype, device=device)\n",
    "    vec[vocab[label]] = 1.0\n",
    "    return vec\n",
    "\n",
    "def stiffness_to_node_adj_edge_index(K: torch.Tensor, num_nodes: int, dof_per_node: int = 3) -> torch.Tensor: #mesh-mesh nodes\n",
    "    K = K.coalesce()\n",
    "    dof_rows, dof_cols = K.indices()\n",
    "    node_rows = torch.div(dof_rows, dof_per_node, rounding_mode=\"floor\")\n",
    "    node_cols = torch.div(dof_cols, dof_per_node, rounding_mode=\"floor\")\n",
    "    ei = torch.stack([node_rows.long(), node_cols.long()], dim=0)\n",
    "    mask = ei[0] != ei[1]\n",
    "    ei = ei[:, mask]\n",
    "    ei = torch.unique(ei, dim=1)\n",
    "    return ei\n",
    "\n",
    "def incidence_edges_from_conn(conn: np.ndarray, nodes: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    Nc, Nv = conn.shape\n",
    "    c_idx = np.repeat(np.arange(Nc, dtype=np.int64), Nv)\n",
    "    n_idx = conn.reshape(-1)\n",
    "    edge_index = torch.from_numpy(np.vstack([c_idx, n_idx])).long()\n",
    "    node_tensor = nodes.to(edge_index.device)\n",
    "    conn_tensor = torch.from_numpy(conn).long().to(edge_index.device)\n",
    "    #edge attribute -> mesh to element centroid in xyz\n",
    "    elem_nodes = node_tensor[conn_tensor]\n",
    "    centroids = elem_nodes.mean(dim=1, keepdim=True)\n",
    "    rel_disp = (elem_nodes - centroids).reshape(-1, elem_nodes.size(-1))\n",
    "\n",
    "    return edge_index, rel_disp\n",
    "\n",
    "# Connectivity\n",
    "# mesh nodes <-> mesh nodes\n",
    "# mesh nodes <-> element nodes\n",
    "\n",
    "def data_to_graph(idx, path:str,materials_csv:str,device):\n",
    "    data = HeteroData()\n",
    "    vocab, sim_to_label = load_material_vocab(materials_csv)\n",
    "    simdata = torch.load(path)\n",
    "    idx = idx\n",
    "    conn = simdata[\"elements\"]\n",
    "    conn = conn.cpu().numpy() if isinstance(conn, torch.Tensor) else np.asarray(conn)\n",
    "    nodes = simdata['nodes']\n",
    "    label = sim_to_label[idx]\n",
    "    c2n_ei, c2n_w = incidence_edges_from_conn(conn,nodes)  # [2, E_cn], [E_cn, 1]\n",
    "    \n",
    "    # mesh node properties: positions, internal forces, BC, dirichlet displacement\n",
    "    ##TODO: add external forces\n",
    "    data['nodes'].pos = nodes #                                             [N,3]\n",
    "    data['nodes'].f_ts = simdata['forces'] #forces in timeseries format     [T,N,3]\n",
    "    data['nodes'].bc = simdata['boundary'] #                                [N,3]\n",
    "    data['nodes'].dr = simdata['dirichlet_disp'] #dirichlet displacement    [N,3]\n",
    "\n",
    "    # element node properties: material, stiffness matrix\n",
    "    data['elements'].material = one_hot(label, vocab, device=device).unsqueeze(0).repeat(int(conn.shape[0]), 1) # [E,len(materials)]\n",
    "    #data['elements'].stiffness = #stiffness is a learned feature\n",
    "\n",
    "    # target properties\n",
    "    # mesh: displacement over time\n",
    "    # element: stress, damage state\n",
    "    data['nodes'].u_ts = simdata['u_history']\n",
    "    data['elements'].s_ts = simdata['stress_history']\n",
    "    data['elements'].d_ts = simdata['state']\n",
    "\n",
    "    # edges: connectivity mesh-mesh, mesh-element\n",
    "    # mesh-element: distance to element centroid\n",
    "    data[\"elements\", \"contributes\", \"nodes\"].edge_index = c2n_ei\n",
    "    data[\"elements\", \"contributes\", \"nodes\"].edge_attr = c2n_w\n",
    "    data[\"nodes\", \"belongs_to\", \"elements\"].edge_index = c2n_ei.flip(0)\n",
    "    data[\"nodes\", \"belongs_to\", \"elements\"].edge_attr = -c2n_w\n",
    "    data['elements'].num_nodes = simdata['stress_history'].size(1)\n",
    "\n",
    "    # mesh-mesh: distance\n",
    "    ei = stiffness_to_node_adj_edge_index(simdata[\"stiffness\"], num_nodes=nodes.size(0), dof_per_node=nodes.size(1))\n",
    "    data[\"nodes\", \"adjacent\", \"nodes\"].edge_index = ei\n",
    "    data[\"nodes\", \"adjacent_rev\", \"nodes\"].edge_index = ei.flip(0)\n",
    "    data[\"nodes\", \"adjacent\", \"nodes\"].edge_attr = (nodes[ei[1]] - nodes[ei[0]]).float()\n",
    "\n",
    "    #data['elements'].edge_index = simdata['elements'] #mesh-element [E,8]\n",
    "    #data['nodes'].edge_index = stiffness_to_node_adj_edge_index(simdata[\"stiffness\"], num_nodes=nodes.size(0), dof_per_node=nodes.size(1)) #from stiffness matrix, only connectivity\n",
    "\n",
    "    # for debugging dimensions\n",
    "    #print(data['nodes'].num_nodes)                              # N\n",
    "    #print(data['elements'].num_nodes)                           # E\n",
    "    #print(data.num_edges)                                       # 2*((E*num_vertices)+())\n",
    "    #print(data['nodes','adjacent','nodes'].num_edges)           # \n",
    "    #print(data['nodes','adjacent_rev','nodes'].num_edges)       #\n",
    "    #print(data['elements','contributes','nodes'].num_edges)     # E*num_vertices\n",
    "    #print(data['nodes','belongs_to','elements'].num_edges)      # E*num_vertices\n",
    "\n",
    "    #data = data.pin_memory()\n",
    "    data = data.to(device)\n",
    "    return data\n",
    "\n",
    "#data_to_graph('../base/torchfem_dataset/processed/simulation_dump_3.pt','../base/torchfem_dataset/processed/mat.csv',device)\n",
    "\n",
    "def generate_dataset(data_dir:str,materials_csv:str):\n",
    "    device = torch.device('cpu')\n",
    "    files = sorted(Path(data_dir).glob(\"simulation_dump*.pt\"))\n",
    "    samples = []\n",
    "    for file in files:\n",
    "        idx = int(str(file).split(\"simulation_dump_\")[1].split(\".pt\")[0])\n",
    "        data = data_to_graph(idx,file,materials_csv,device)\n",
    "        samples.append(data)\n",
    "        print(file)\n",
    "    print(len(files))\n",
    "    return samples\n",
    "\n",
    "dataset = generate_dataset('../base/torchfem_dataset/panel_euler/panel_plasticity','../base/torchfem_dataset/processed/mat.csv')\n",
    "torch.save(dataset, \"../base/torchfem_dataset/processed/panel_combined.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f58b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_100.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_101.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_102.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_103.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_104.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_105.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_106.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_107.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_108.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_109.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_11.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_110.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_112.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_114.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_115.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_117.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_118.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_119.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_121.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_122.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_124.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_126.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_128.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_129.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_13.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_131.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_132.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_134.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_135.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_137.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_138.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_140.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_141.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_142.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_143.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_146.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_147.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_148.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_149.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_150.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_16.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_17.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_18.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_19.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_2.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_20.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_23.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_24.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_25.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_26.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_27.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_29.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_3.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_30.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_31.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_32.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_33.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_34.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_36.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_38.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_4.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_40.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_41.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_42.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_43.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_44.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_45.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_47.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_48.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_50.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_51.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_52.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_54.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_56.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_57.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_58.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_59.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_6.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_60.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_61.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_62.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_63.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_64.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_65.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_66.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_68.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_69.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_7.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_70.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_71.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_72.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_73.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_74.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_75.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_76.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_8.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_82.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_83.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_84.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_85.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_87.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_88.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_89.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_9.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_90.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_91.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_92.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_94.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_95.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_96.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_97.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_98.pt\n",
      "..\\torchfem_dataset\\panel_plasticity_2\\simulation_dump_99.pt\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "## PyG Graph with Mesh & Element Nodes - material already in sim data\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import pandas as pd\n",
    "\n",
    "# Material encoding (1-h)\n",
    "def load_material_vocab() -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    # CSV: idx,label\n",
    "    #df = pd.read_csv(materials_csv, header=None, names=[\"sim_id\", \"label\"])\n",
    "    #labels = sorted(df[\"label\"].astype(str).unique().tolist())\n",
    "    labels = ['concrete','steel','aluminum','CFRP'] #0,1,2,3 fixed material labels for now\n",
    "    vocab = {lbl: i for i, lbl in enumerate(labels)}\n",
    "    return vocab\n",
    "\n",
    "def one_hot(label: str, vocab: Dict[str, int], device=None, dtype=torch.float) -> torch.Tensor:\n",
    "    vec = torch.zeros(len(vocab), dtype=dtype, device=device)\n",
    "    vec[vocab[label]] = 1.0\n",
    "    return vec\n",
    "\n",
    "def stiffness_to_node_adj_edge_index(K: torch.Tensor, num_nodes: int, dof_per_node: int = 3) -> torch.Tensor: #mesh-mesh nodes\n",
    "    K = K.coalesce()\n",
    "    dof_rows, dof_cols = K.indices()\n",
    "    node_rows = torch.div(dof_rows, dof_per_node, rounding_mode=\"floor\")\n",
    "    node_cols = torch.div(dof_cols, dof_per_node, rounding_mode=\"floor\")\n",
    "    ei = torch.stack([node_rows.long(), node_cols.long()], dim=0)\n",
    "    mask = ei[0] != ei[1]\n",
    "    ei = ei[:, mask]\n",
    "    ei = torch.unique(ei, dim=1)\n",
    "    return ei\n",
    "\n",
    "def incidence_edges_from_conn(conn: np.ndarray, nodes: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    Nc, Nv = conn.shape\n",
    "    c_idx = np.repeat(np.arange(Nc, dtype=np.int64), Nv)\n",
    "    n_idx = conn.reshape(-1)\n",
    "    edge_index = torch.from_numpy(np.vstack([c_idx, n_idx])).long()\n",
    "    node_tensor = nodes.to(edge_index.device)\n",
    "    conn_tensor = torch.from_numpy(conn).long().to(edge_index.device)\n",
    "    #edge attribute -> mesh to element centroid in xyz\n",
    "    elem_nodes = node_tensor[conn_tensor]\n",
    "    centroids = elem_nodes.mean(dim=1, keepdim=True)\n",
    "    rel_disp = (elem_nodes - centroids).reshape(-1, elem_nodes.size(-1))\n",
    "\n",
    "    return edge_index, rel_disp\n",
    "\n",
    "# Connectivity\n",
    "# mesh nodes <-> mesh nodes\n",
    "# mesh nodes <-> element nodes\n",
    "\n",
    "def data_to_graph(path:str,device):\n",
    "    data = HeteroData()\n",
    "    vocab = load_material_vocab()\n",
    "    simdata = torch.load(path,weights_only=False)\n",
    "    conn = simdata[\"elements\"]\n",
    "    conn = conn.cpu().numpy() if isinstance(conn, torch.Tensor) else np.asarray(conn)\n",
    "    nodes = simdata['nodes']\n",
    "    label = simdata['material']\n",
    "    c2n_ei, c2n_w = incidence_edges_from_conn(conn,nodes)  # [2, E_cn], [E_cn, 1]\n",
    "    \n",
    "    # mesh node properties: positions, internal forces, BC, dirichlet displacement\n",
    "    data['nodes'].pos = nodes #                                             [N,3]\n",
    "    data['nodes'].f_ext = simdata['ext_forces'] #external forces            [T,N,3]\n",
    "    data['nodes'].bc = simdata['boundary'] #                                [N,3]\n",
    "    #data['nodes'].dr = simdata['dirichlet_disp'] #dirichlet displacement   [N,3]\n",
    "\n",
    "    # element node properties: material, stiffness matrix\n",
    "    data['elements'].material = one_hot(label, vocab, device=device).unsqueeze(0).repeat(int(conn.shape[0]), 1) # [E,len(materials)]\n",
    "    #data['elements'].stiffness = #stiffness is a learned feature\n",
    "\n",
    "    # target properties\n",
    "    # mesh: displacement over time\n",
    "    # element: stress, damage state, internal forces\n",
    "    data['nodes'].u_ts = simdata['u_history'] #                                     [T,N,3]\n",
    "    data['elements'].s_ts = simdata['stress_history'] #                             [T,E,3]\n",
    "    data['elements'].d_ts = simdata['state']\n",
    "    data['nodes'].f_int = simdata['forces'] #internal forces in timeseries format     [T,N,3]\n",
    "\n",
    "    # edges: connectivity mesh-mesh, mesh-element\n",
    "    # mesh-element: distance to element centroid\n",
    "    data[\"elements\", \"contributes\", \"nodes\"].edge_index = c2n_ei\n",
    "    data[\"elements\", \"contributes\", \"nodes\"].edge_attr = c2n_w\n",
    "    data[\"nodes\", \"belongs_to\", \"elements\"].edge_index = c2n_ei.flip(0)\n",
    "    data[\"nodes\", \"belongs_to\", \"elements\"].edge_attr = c2n_w.flip(0)\n",
    "    data['elements'].num_nodes = simdata['stress_history'].size(1)\n",
    "\n",
    "    # mesh-mesh: distance\n",
    "    ei = stiffness_to_node_adj_edge_index(simdata[\"stiffness\"], num_nodes=nodes.size(0), dof_per_node=nodes.size(1))\n",
    "    data[\"nodes\", \"adjacent\", \"nodes\"].edge_index = ei\n",
    "    data[\"nodes\", \"adjacent_rev\", \"nodes\"].edge_index = ei.flip(0)\n",
    "    data[\"nodes\", \"adjacent\", \"nodes\"].edge_attr = (nodes[ei[1]] - nodes[ei[0]]).float()\n",
    "\n",
    "    #data['elements'].edge_index = simdata['elements'] #mesh-element [E,8]\n",
    "    #data['nodes'].edge_index = stiffness_to_node_adj_edge_index(simdata[\"stiffness\"], num_nodes=nodes.size(0), dof_per_node=nodes.size(1)) #from stiffness matrix, only connectivity\n",
    "\n",
    "    # for debugging dimensions\n",
    "    #print(data['nodes'].num_nodes)                              # N\n",
    "    #print(data['elements'].num_nodes)                           # E\n",
    "    #print(data.num_edges)                                       # 2*((E*num_vertices)+())\n",
    "    #print(data['nodes','adjacent','nodes'].num_edges)           # \n",
    "    #print(data['nodes','adjacent_rev','nodes'].num_edges)       #\n",
    "    #print(data['elements','contributes','nodes'].num_edges)     # E*num_vertices\n",
    "    #print(data['nodes','belongs_to','elements'].num_edges)      # E*num_vertices\n",
    "\n",
    "    #data = data.pin_memory()\n",
    "    data = data.to(device)\n",
    "    return data\n",
    "\n",
    "#data_to_graph('../torchfem_dataset/panel_plasticity_2/simulation_dump_3.pt',device)\n",
    "\n",
    "def generate_dataset(data_dir:str):\n",
    "    device = torch.device('cpu')\n",
    "    files = sorted(Path(data_dir).glob(\"simulation_dump*.pt\"))\n",
    "    samples = []\n",
    "    for file in files:\n",
    "        data = data_to_graph(file,device)\n",
    "        samples.append(data)\n",
    "        print(file)\n",
    "    print(len(files))\n",
    "    return samples\n",
    "\n",
    "dataset = generate_dataset('../torchfem_dataset/panel_plasticity_2')\n",
    "torch.save(dataset, \"../torchfem_dataset/panel_plasticity_2/panel_combined_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac5d979e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4340.0, 4400.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "forces = dataset[0]['nodes']['f_int'][10]*1e-2\n",
    "forces_e = dataset[0]['nodes']['f_ext'][10]*5e-1\n",
    "disp = dataset[0]['nodes']['u_ts'][10]*50\n",
    "boundary = dataset[0]['nodes']['bc']\n",
    "plt.plot(boundary)\n",
    "#plt.plot(forces,'r')\n",
    "#plt.plot(forces_e,'b')\n",
    "plt.plot(disp,'k')\n",
    "plt.xlim(4340,4400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb77dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dataset = torch.load(\"../torchfem_dataset/panel_plasticity_2/panel_combined.pt\",weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9fd81b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['nodes', 'elements'], [('elements', 'contributes', 'nodes'), ('nodes', 'belongs_to', 'elements'), ('nodes', 'adjacent', 'nodes'), ('nodes', 'adjacent_rev', 'nodes')])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Tried to collect 'x' but did not find any occurrences of it in any node and/or edge type\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m total_correct / total_examples\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m21\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     val_acc = test(val_loader)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     64\u001b[39m model.train()\n\u001b[32m     65\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m out = model(\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx_dict\u001b[49m, data.edge_index_dict)\n\u001b[32m     67\u001b[39m mask = data[\u001b[33m'\u001b[39m\u001b[33mpaper\u001b[39m\u001b[33m'\u001b[39m].train_mask\n\u001b[32m     68\u001b[39m loss = F.cross_entropy(out[\u001b[33m'\u001b[39m\u001b[33mpaper\u001b[39m\u001b[33m'\u001b[39m][mask], data[\u001b[33m'\u001b[39m\u001b[33mpaper\u001b[39m\u001b[33m'\u001b[39m].y[mask])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bm_tu\\Desktop\\gnn\\gnn_312\\Lib\\site-packages\\torch_geometric\\data\\hetero_data.py:161\u001b[39m, in \u001b[36mHeteroData.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._global_store, key)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(re.search(\u001b[33m'\u001b[39m\u001b[33m_dict$\u001b[39m\u001b[33m'\u001b[39m, key)):\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has no \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mattribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bm_tu\\Desktop\\gnn\\gnn_312\\Lib\\site-packages\\torch_geometric\\data\\hetero_data.py:651\u001b[39m, in \u001b[36mHeteroData.collect\u001b[39m\u001b[34m(self, key, allow_empty)\u001b[39m\n\u001b[32m    649\u001b[39m         mapping[subtype] = \u001b[38;5;28mgetattr\u001b[39m(store, key)\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_empty \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapping) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTried to collect \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m but did not find any \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    652\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33moccurrences of it in any node and/or edge type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mapping\n",
      "\u001b[31mKeyError\u001b[39m: \"Tried to collect 'x' but did not find any occurrences of it in any node and/or edge type\""
     ]
    }
   ],
   "source": [
    "## Heterogeneous Graph Transformer - Dynamic over timesteps\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SAGEConv, to_hetero, HGTConv, Linear\n",
    "from forward_src.hgt_conv import *\n",
    "from forward_src.hgt_model import GNN, Matcher\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "#dataset = torch.load(\"../torchfem_dataset/panel_plasticity_2/panel_combined.pt\",weights_only=False)\n",
    "print(dataset[0].metadata())\n",
    "device = 'cpu'\n",
    "data = dataset[1]\n",
    "#print(graph.keys)\n",
    "\n",
    "data = T.AddSelfLoops()(data)\n",
    "data = T.NormalizeFeatures()(data)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in data.node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(),\n",
    "                           num_heads)\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = {\n",
    "            node_type: self.lin_dict[node_type](x).relu_()\n",
    "            for node_type, x in x_dict.items()\n",
    "        }\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "\n",
    "        return self.lin(x_dict['author'])\n",
    "\n",
    "model = GNN(hidden_channels=64, out_channels=2)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['paper'].train_mask\n",
    "    loss = F.cross_entropy(out['paper'][mask], data['paper'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f11b4f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): ModuleDict(\n",
       "    (elements__contributes__nodes): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (nodes__belongs_to__elements): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (nodes__adjacent__nodes): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (nodes__adjacent_rev__nodes): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "  )\n",
       "  (conv2): ModuleDict(\n",
       "    (elements__contributes__nodes): SAGEConv((-1, -1), 2, aggr=mean)\n",
       "    (nodes__belongs_to__elements): SAGEConv((-1, -1), 2, aggr=mean)\n",
       "    (nodes__adjacent__nodes): SAGEConv((-1, -1), 2, aggr=mean)\n",
       "    (nodes__adjacent_rev__nodes): SAGEConv((-1, -1), 2, aggr=mean)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training loop - direct import from HGT\n",
    "from torch_geometric.data import DataLoader\n",
    "from forward_src.hgt_conv import *\n",
    "from forward_src.hgt_model import GNN, Matcher\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "dataset = torch.load(\"../torchfem_dataset/panel_plasticity_2/panel_combined.pt\",weights_only=False)\n",
    "print(dataset[0].metadata())\n",
    "device = 'cpu'\n",
    "graph = dataset[1]\n",
    "#print(graph.keys)\n",
    "\n",
    "types = graph.node_types\n",
    "\n",
    "gnn = GNN(conv_name='hgt',in_dim=len(graph['nodes']),n_hid=64,n_heads=2,\n",
    "          n_layers=3,dropout=0.1,num_types=len(types),num_relations=len(graph.edge_types)+1)\n",
    "matcher = Matcher(64).to(device)\n",
    "model = nn.Sequential(gnn,matcher)\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 1000, eta_min=1e-6)\n",
    "loader = DataLoader(dataset)\n",
    "\n",
    "def mask_softmax(pred, size):\n",
    "    loss = 0\n",
    "    stx = 0\n",
    "    for l in size:\n",
    "        loss += torch.log_softmax(pred[stx: stx + l], dim=-1)[0] / np.log(l)\n",
    "        stx += l\n",
    "    return -loss\n",
    "\n",
    "stats = []\n",
    "res = []\n",
    "best_val   = 0\n",
    "train_step = 1500\n",
    "\n",
    "sample = next(iter(loader))\n",
    "print(sample)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    #torch.cuda.empty_cache()\n",
    "\n",
    "    for _ in range(2):\n",
    "        for node_feature, node_type, edge_time, edge_index, edge_type, ylabel in train_data:\n",
    "            node_rep = gnn.forward(node_feature.to(device), node_type.to(device),\n",
    "                edge_time.to(device), edge_index.to(device), edge_type.to(device))\n",
    "            author_key = []\n",
    "            paper_key  = []\n",
    "            key_size   = []\n",
    "            for paper_id in ylabel:\n",
    "                author_ids  = ylabel[paper_id]\n",
    "                paper_key  += [np.repeat(paper_id, len(author_ids))]\n",
    "                author_key += [author_ids]\n",
    "                key_size   += [len(author_ids)]\n",
    "            paper_key  = torch.LongTensor(np.concatenate(paper_key)).to(device)\n",
    "            author_key = torch.LongTensor(np.concatenate(author_key)).to(device)\n",
    "\n",
    "            train_paper_vecs  = node_rep[paper_key]\n",
    "            train_author_vecs = node_rep[author_key]\n",
    "            res = matcher.forward(train_author_vecs, train_paper_vecs, pair=True)\n",
    "            loss = mask_softmax(res, key_size)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            torch.cuda.empty_cache()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses += [loss.cpu().detach().tolist()]\n",
    "            train_step += 1\n",
    "            scheduler.step(train_step)\n",
    "            del res, loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        node_feature, node_type, edge_time, edge_index, edge_type, ylabel = valid_data\n",
    "        node_rep = gnn.forward(node_feature.to(device), node_type.to(device), \\\n",
    "                                   edge_time.to(device), edge_index.to(device), edge_type.to(device))\n",
    "\n",
    "        author_key = []\n",
    "        paper_key  = []\n",
    "        key_size   = []\n",
    "        for paper_id in ylabel:\n",
    "            author_ids  = ylabel[paper_id]\n",
    "            paper_key  += [np.repeat(paper_id, len(author_ids))]\n",
    "            author_key += [author_ids]\n",
    "            key_size   += [len(author_ids)]\n",
    "        paper_key  = torch.LongTensor(np.concatenate(paper_key)).to(device)\n",
    "        author_key = torch.LongTensor(np.concatenate(author_key)).to(device)\n",
    "        \n",
    "        valid_paper_vecs  = node_rep[paper_key]\n",
    "        valid_author_vecs = node_rep[author_key]\n",
    "        res = matcher.forward(valid_author_vecs, valid_paper_vecs, pair=True)\n",
    "        loss = mask_softmax(res, key_size)\n",
    "        '''\n",
    "            Calculate Valid NDCG. Update the best model based on highest NDCG score.\n",
    "        '''\n",
    "        valid_res = []\n",
    "        ser = 0\n",
    "        for s in key_size:\n",
    "            p = res[ser: ser + s]\n",
    "            l = torch.zeros(s)\n",
    "            l[0] = 1\n",
    "            r = l[p.argsort(descending = True)]\n",
    "            valid_res += [r.cpu().detach().tolist()]\n",
    "            ser += s\n",
    "        valid_ndcg = np.average([ndcg_at_k(resi, len(resi)) for resi in valid_res])\n",
    "        valid_mrr  = np.average(mean_reciprocal_rank(valid_res))\n",
    "        \n",
    "        if valid_ndcg > best_val:\n",
    "            best_val = valid_ndcg\n",
    "            torch.save(model, os.path.join(args.model_dir, args.task_name + '_' + args.conv_name))\n",
    "            print('UPDATE!!!')\n",
    "        \n",
    "        st = time.time()\n",
    "        print((\"Epoch: %d (%.1fs)  LR: %.5f Train Loss: %.2f  Valid Loss: %.2f  Valid NDCG: %.4f  Valid MRR: %.4f\") % \\\n",
    "              (epoch, (st-et), optimizer.param_groups[0]['lr'], np.average(train_losses), \\\n",
    "                    loss.cpu().detach().tolist(), valid_ndcg, valid_mrr))\n",
    "        stats += [[np.average(train_losses), loss.cpu().detach().tolist()]]\n",
    "        del res, loss\n",
    "    del train_data, valid_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GraphNet Architecture\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GraphNetBlock(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, global_dim=0, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.global_dim = global_dim\n",
    "\n",
    "        # Edge update ^e\n",
    "        in_dim_e = edge_dim + 2*node_dim + global_dim\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim_e, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, edge_dim)\n",
    "        )\n",
    "\n",
    "        # Node update ^v\n",
    "        in_dim_v = node_dim + edge_dim + global_dim\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim_v, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, node_dim)\n",
    "        )\n",
    "\n",
    "        self.global_mlp = None\n",
    "\n",
    "    def forward(self, nodes, edges, senders, receivers, global_attr=None):\n",
    "        N, E = nodes.size(0), edges.size(0)\n",
    "\n",
    "        g_e = torch.zeros(E, 0, device=nodes.device)\n",
    "        g_v = torch.zeros(N, 0, device=nodes.device)\n",
    "\n",
    "        # ---- Edge update ----\n",
    "        #print(edges.shape, nodes[senders].shape, nodes[receivers].shape, g_e.shape)\n",
    "        edge_inputs = torch.cat([edges, nodes[senders], nodes[receivers], g_e], dim=-1)\n",
    "        edges_updated = self.edge_mlp(edge_inputs)\n",
    "\n",
    "        # ---- Node update ----\n",
    "        agg_messages = torch.zeros(N, edges_updated.size(-1), device=nodes.device)\n",
    "        agg_messages.index_add_(0, receivers, edges_updated)  # ^{ev} = sum\n",
    "        node_inputs = torch.cat([nodes, agg_messages, g_v], dim=-1)\n",
    "        nodes_updated = self.node_mlp(node_inputs)\n",
    "\n",
    "        return nodes_updated, edges_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac75597",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM-Type Architecture with rollout\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def reset_weights(m):\n",
    "    if hasattr(m, \"reset_parameters\"):\n",
    "        m.reset_parameters()\n",
    "\n",
    "class GraphTemporalModel(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.gn = GraphNetBlock(node_dim, edge_dim)\n",
    "        self.rnn = nn.LSTM(input_size=node_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.decoder = nn.Linear(hidden_dim, out_dim)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.gn.apply(reset_weights)\n",
    "        for name, param in self.rnn.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "        nn.init.xavier_uniform_(self.decoder.weight)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x_t, edge_features, senders, receivers, h=None, c=None):\n",
    "        \"\"\"\n",
    "        One-step prediction:\n",
    "          x_t : [B, N, F]  current node features\n",
    "          edge_features : [E, d_e]\n",
    "          senders, receivers : [E]\n",
    "          h, c : LSTM hidden + cell state\n",
    "        Returns:\n",
    "          x_next : [B, N, out_dim]\n",
    "          (h, c) : updated hidden states\n",
    "        \"\"\"\n",
    "        # Graph update\n",
    "        gn_out, _ = self.gn(x_t, edge_features, senders, receivers)  # [B, N, F]\n",
    "\n",
    "        # Reshape node features for RNN (flatten nodes as features)\n",
    "        rnn_in = gn_out.reshape(gn_out.size(0), 1, -1)  # [B, 1, N*F]\n",
    "\n",
    "        # RNN step\n",
    "        if h is not None and c is not None:\n",
    "            rnn_out, (h, c) = self.rnn(rnn_in, (h, c))\n",
    "        else:\n",
    "            rnn_out, (h, c) = self.rnn(rnn_in)\n",
    "\n",
    "        # Decode next node features\n",
    "        x_next = self.decoder(rnn_out)  # [B, 1, out_dim]\n",
    "        x_next = x_next.squeeze(1)      # [B, out_dim]\n",
    "\n",
    "        return x_next, (h, c)\n",
    "\n",
    "    def rollout(self, node_init, edge_features, senders, receivers, steps): ##TODO: time-dependent\n",
    "        \"\"\"\n",
    "        Autoregressive rollout for multiple steps.\n",
    "          node_init : [B, N, F]  initial node features\n",
    "          steps     : number of rollout steps\n",
    "        Returns:\n",
    "          preds : [B, steps, out_dim]\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        x_t = node_init\n",
    "        h, c = None, None\n",
    "\n",
    "        for _ in range(steps):\n",
    "            x_t, (h, c) = self.forward(x_t, edge_features, senders, receivers, h, c)\n",
    "            preds.append(x_t)\n",
    "\n",
    "        return torch.stack(preds, dim=1)  # [B, steps, out_dim]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7706c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM-Type Architecture without rollout\n",
    "\n",
    "def reset_weights(m):\n",
    "    if hasattr(m, \"reset_parameters\"):\n",
    "        m.reset_parameters()\n",
    "\n",
    "class GraphTemporalModelNoRollout(nn.Module):\n",
    "    def __init__(self, static_dim, state_dim, cond_dim, edge_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.static_dim = static_dim\n",
    "        self.state_dim = state_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        self.node_dim = static_dim + state_dim + cond_dim\n",
    "\n",
    "        self.gn = GraphNetBlock(self.node_dim, edge_dim)\n",
    "        self.rnn = nn.LSTM(input_size=self.node_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.decoder = nn.Linear(hidden_dim, self.state_dim)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.gn.apply(reset_weights)\n",
    "        for name, param in self.rnn.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "        nn.init.xavier_uniform_(self.decoder.weight)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "\n",
    "    def forward(self, state_t, cond_t, static_feat, edge_features, senders, receivers, hc=None):\n",
    "        # combine current prediction with known context\n",
    "        nodes = torch.cat([static_feat, state_t, cond_t], dim=-1)\n",
    "        \n",
    "        nodes, _ = self.gn(nodes, edge_features, senders, receivers)\n",
    "\n",
    "        #rnn_in = nodes.reshape(1, 1, -1) if nodes.dim() == 2 else nodes.reshape(nodes.size(0), 1, -1)\n",
    "        #print(self.state_dim,self.node_dim,nodes.shape)\n",
    "        #print(nodes.shape,edge_features.shape,senders.shape,receivers.shape)\n",
    "        rnn_out, hc = self.rnn(nodes, hc) if hc else self.rnn(nodes)\n",
    "        #rnn_out, hc = self.rnn(rnn_in, hc) if hc else self.rnn(rnn_in)\n",
    "        next_state = self.decoder(rnn_out.squeeze(1)).view_as(state_t)\n",
    "        return next_state, hc\n",
    "\n",
    "    def rollout(self, state_init, cond_seq, static_feat, edge_features, senders, receivers):\n",
    "        preds = []\n",
    "        state = state_init\n",
    "        hc = None\n",
    "        for cond_t in cond_seq:\n",
    "            state, hc = self.forward(state, cond_t, static_feat, edge_features, senders, receivers, hc)\n",
    "            preds.append(state)\n",
    "        return torch.stack(preds, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef47f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "simdata = torch.load('../torchfem_dataset/panel_plasticity/simulation_dump_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce22f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Dataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class GraphSeqDataset(Dataset):\n",
    "    def __init__(self, pt_path):\n",
    "        raw = torch.load(pt_path, map_location=\"cpu\")\n",
    "        # assume file is either a list[dict] or a dict of tensors\n",
    "        if isinstance(raw, dict) and all(torch.is_tensor(v) for v in raw.values()):\n",
    "            self.samples = [\n",
    "                {k: v[i] for k, v in raw.items()}\n",
    "                for i in range(next(iter(raw.values())).size(0))\n",
    "            ]\n",
    "        else:\n",
    "            self.samples = raw\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        return {\n",
    "            \"node_features\": sample[\"node_features\"].float(),\n",
    "            \"edge_features\": sample[\"edge_features\"].float(),\n",
    "            \"senders\": sample[\"senders\"].long(),\n",
    "            \"receivers\": sample[\"receivers\"].long(),\n",
    "            \"target\": sample.get(\"target\", sample[\"node_features\"]).float(),\n",
    "        }\n",
    "\n",
    "def graph_collate(batch):\n",
    "    # handles batch size >1; adjust if sequences have different lengths\n",
    "    out = {}\n",
    "    for key in batch[0]:\n",
    "        vals = [item[key] for item in batch]\n",
    "        if key in {\"senders\", \"receivers\"}:\n",
    "            out[key] = torch.stack(vals, dim=0)\n",
    "        else:\n",
    "            out[key] = torch.stack(vals, dim=0)\n",
    "    return out\n",
    "\n",
    "dataset = GraphSeqDataset(\"torchfem_dataset/panel_plasticity/panel_processed.pt\")\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=graph_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n",
      "torch.Size([32670, 9]) torch.Size([32670, 15]) torch.Size([32670, 15]) torch.Size([32670, 0])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     59\u001b[39m receivers = receivers.squeeze(\u001b[32m0\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m#preds = rollout_from_dataset(gn, node_features_seq, edge_features,\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m#    senders, receivers)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m preds = \u001b[43mgn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msenders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreceivers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m preds = preds.permute(\u001b[32m1\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m2\u001b[39m)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# preds covers [1..T-1], align with ground truth\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m#print(preds.shape,target_seq.shape)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mGraphTemporalModel.rollout\u001b[39m\u001b[34m(self, node_init, edge_features, senders, receivers, steps)\u001b[39m\n\u001b[32m     68\u001b[39m h, c = \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     x_t, (h, c) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msenders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreceivers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     preds.append(x_t)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack(preds, dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mGraphTemporalModel.forward\u001b[39m\u001b[34m(self, x_t, edge_features, senders, receivers, h, c)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03mOne-step prediction:\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m  x_t : [B, N, F]  current node features\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m \u001b[33;03m  (h, c) : updated hidden states\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Graph update\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m gn_out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msenders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreceivers\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [B, N, F]\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Reshape node features for RNN (flatten nodes as features)\u001b[39;00m\n\u001b[32m     44\u001b[39m rnn_in = gn_out.reshape(gn_out.size(\u001b[32m0\u001b[39m), \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [B, 1, N*F]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mGraphNetBlock.forward\u001b[39m\u001b[34m(self, nodes, edges, senders, receivers, global_attr)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(edges.shape, nodes[senders].shape, nodes[receivers].shape, g_e.shape)\n\u001b[32m     37\u001b[39m edge_inputs = torch.cat([edges, nodes[senders], nodes[receivers], g_e], dim=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m edges_updated = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43medge_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# ---- Node update ----\u001b[39;00m\n\u001b[32m     41\u001b[39m agg_messages = torch.zeros(N, edges_updated.size(-\u001b[32m1\u001b[39m), device=nodes.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/modules/activation.py:101\u001b[39m, in \u001b[36mReLU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gnn/gnn_312/lib/python3.12/site-packages/torch/nn/functional.py:1473\u001b[39m, in \u001b[36mrelu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   1471\u001b[39m     result = torch.relu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# GraphNet training loop - LSTM\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import time\n",
    "\n",
    "#dataset = torch.load('torchfem_dataset/panel_plasticity/simulation_.pt')\n",
    "#loader = DataLoader(dataset, batch_size=1, shuffle=True)  # batch size 1 for rollout\n",
    "device = 'cuda:0'\n",
    "loader = DataLoader(dataset, batch_size=1, collate_fn=graph_collate)\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "node_dim = sample[\"node_features\"].shape[-1]\n",
    "edge_dim = sample[\"edge_features\"].shape[-1]\n",
    "out_dim = node_dim                # or whatever target width you predict\n",
    "\n",
    "gn = GraphTemporalModel(\n",
    "    node_dim=node_dim,\n",
    "    edge_dim=edge_dim,\n",
    "    hidden_dim=128,\n",
    "    out_dim=out_dim,\n",
    ").to(device)\n",
    "gn.apply(reset_weights)\n",
    "\n",
    "optimizer = optim.AdamW(gn.parameters(), lr=5e-2)\n",
    "loss_fn = nn.SmoothL1Loss() ##TODO: physics-informed loss\n",
    "epochs = 10\n",
    "losses = []\n",
    "\n",
    "def rollout_from_dataset(gn, node_features_seq, edge_features, \n",
    "                         senders, receivers):\n",
    "    \"\"\"\n",
    "    Unroll the GN across the sequence length T.\n",
    "    \"\"\"\n",
    "    T, N, F = node_features_seq.shape[0], node_features_seq.shape[1], node_features_seq.shape[1:]\n",
    "    preds = []\n",
    "\n",
    "    nodes_t = node_features_seq[0]  # initial state\n",
    "    for t in range(T-1):\n",
    "        # forward pass\n",
    "        #print(nodes_t.shape,edge_features.shape,senders.shape,receivers.shape)\n",
    "        nodes_t, _= gn(nodes_t, edge_features, senders, receivers) #nodes_t,_,_\n",
    "        preds.append(nodes_t)   # keep entire state prediction\n",
    "    return torch.stack(preds, dim=0)  # [T-1, N, F]\n",
    "\n",
    "max_batches = 5\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        if batch_idx >= max_batches:\n",
    "            break\n",
    "        node_features_seq, edge_features, senders, receivers, target_seq = batch['node_features'],batch['edge_features'],batch['senders'],batch['receivers'],batch['node_features']\n",
    "        \n",
    "        node_features_seq = node_features_seq.squeeze(0)      # [T,N,F]\n",
    "        steps = node_features_seq.shape[0]\n",
    "        edge_features = edge_features.squeeze(0)              # [E,D]\n",
    "        #global_features_seq = global_features_seq.squeeze(0)  # [T,G]\n",
    "        target_seq = target_seq.squeeze(0)                    # [T,N,out_dim]\n",
    "        senders = senders.squeeze(0)\n",
    "        receivers = receivers.squeeze(0)\n",
    "        #preds = rollout_from_dataset(gn, node_features_seq, edge_features,\n",
    "        #    senders, receivers)\n",
    "\n",
    "        preds = gn.rollout(node_features_seq[0], edge_features, senders, receivers, steps)\n",
    "        preds = preds.permute(1,0,2)\n",
    "        # preds covers [1..T-1], align with ground truth\n",
    "        #print(preds.shape,target_seq.shape)\n",
    "        loss = loss_fn(preds[1:], target_seq[1:])  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        #print(total_loss)\n",
    "    losses.append(total_loss)\n",
    "\n",
    "    #if epoch % 20 == 0:\n",
    "    print(f\"Epoch {epoch}, Loss={total_loss/len(loader):.2f}\")\n",
    "torch.save({'model':gn.state_dict(),'optimizer':optimizer.state_dict()},'torchfem_dataset/weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c45f275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss=0.8523\n",
      "Epoch 1, Loss=0.7015\n",
      "Epoch 2, Loss=0.6442\n",
      "Epoch 3, Loss=0.6116\n",
      "Epoch 4, Loss=0.5959\n",
      "Epoch 5, Loss=0.6105\n",
      "Epoch 6, Loss=0.6002\n",
      "Epoch 7, Loss=0.5837\n",
      "Epoch 8, Loss=0.5658\n",
      "Epoch 9, Loss=0.5793\n",
      "Epoch 10, Loss=0.5763\n",
      "Epoch 11, Loss=0.5647\n",
      "Epoch 12, Loss=0.5635\n",
      "Epoch 13, Loss=0.5601\n",
      "Epoch 14, Loss=0.5546\n",
      "Epoch 15, Loss=0.5596\n",
      "Epoch 16, Loss=0.5559\n",
      "Epoch 17, Loss=0.5433\n",
      "Epoch 18, Loss=0.5412\n",
      "Epoch 19, Loss=0.5465\n",
      "Epoch 20, Loss=0.5280\n",
      "Epoch 21, Loss=0.5311\n",
      "Epoch 22, Loss=0.5313\n",
      "Epoch 23, Loss=0.5687\n",
      "Epoch 24, Loss=0.5426\n",
      "Epoch 25, Loss=0.5404\n",
      "Epoch 26, Loss=0.5236\n",
      "Epoch 27, Loss=0.5113\n",
      "Epoch 28, Loss=0.5009\n",
      "Epoch 29, Loss=0.5004\n",
      "Epoch 30, Loss=0.4960\n",
      "Epoch 31, Loss=0.4959\n",
      "Epoch 32, Loss=0.4878\n",
      "Epoch 33, Loss=0.4831\n",
      "Epoch 34, Loss=0.4783\n",
      "Epoch 35, Loss=0.4780\n",
      "Epoch 36, Loss=0.4779\n",
      "Epoch 37, Loss=0.4723\n",
      "Epoch 38, Loss=0.4774\n",
      "Epoch 39, Loss=0.4753\n",
      "Epoch 40, Loss=0.4814\n",
      "Epoch 41, Loss=0.4810\n",
      "Epoch 42, Loss=0.4757\n",
      "Epoch 43, Loss=0.4698\n",
      "Epoch 44, Loss=0.4631\n",
      "Epoch 45, Loss=0.4556\n",
      "Epoch 46, Loss=0.4564\n",
      "Epoch 47, Loss=0.4544\n",
      "Epoch 48, Loss=0.4623\n",
      "Epoch 49, Loss=0.4553\n"
     ]
    }
   ],
   "source": [
    "# GraphNet training loop - LSTM no rollout\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import time\n",
    "\n",
    "#dataset = torch.load('torchfem_dataset/panel_plasticity/simulation_.pt')\n",
    "#loader = DataLoader(dataset, batch_size=1, shuffle=True)  # batch size 1 for rollout\n",
    "device = 'cpu'\n",
    "dataset = GraphSeqDataset(\"torchfem_dataset/panel_plasticity/panel_processed.pt\")\n",
    "loader = DataLoader(dataset, batch_size=1, collate_fn=graph_collate)\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "node_features_seq, edge_features, senders, receivers, target_seq = sample['node_features'],sample['edge_features'],sample['senders'],sample['receivers'],sample['target']\n",
    "\n",
    "\n",
    "node_features_seq = node_features_seq.squeeze(0)        # [T, N, F]\n",
    "time_diff = node_features_seq[1:] - node_features_seq[:-1]\n",
    "dynamic_mask = time_diff.abs().max(dim=0).values > 1e-6 # [N, F]\n",
    "dynamic_mask = dynamic_mask.any(dim=0)                  # [F]\n",
    "static_idx = (~dynamic_mask).nonzero(as_tuple=True)[0]\n",
    "dynamic_idx = dynamic_mask.nonzero(as_tuple=True)[0]\n",
    "static_feat = node_features_seq[0, :, static_idx]                     # [N, static_dim]\n",
    "dynamic_seq = node_features_seq[:, :, dynamic_idx]                    # [T, N, dynamic_dim]\n",
    "state_dim = dynamic_seq.size(-1) // 2\n",
    "state_seq = dynamic_seq[:, :, :state_dim]\n",
    "cond_seq = dynamic_seq[:, :, state_dim:]\n",
    "\n",
    "gn = GraphTemporalModelNoRollout(\n",
    "            static_dim=static_feat.size(-1),\n",
    "            state_dim=state_dim,\n",
    "            cond_dim=cond_seq.size(-1),\n",
    "            edge_dim=edge_features.size(-1),\n",
    "            hidden_dim=128,\n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(gn.parameters(), lr=1e-4)\n",
    "loss_fn = nn.SmoothL1Loss() ##TODO: physics-informed loss\n",
    "epochs = 50\n",
    "losses = []\n",
    "\n",
    "\n",
    "\n",
    "max_batches = 20\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        if batch_idx >= max_batches:\n",
    "            break\n",
    "        node_features_seq, edge_features, senders, receivers, target_seq = batch['node_features'],batch['edge_features'],batch['senders'],batch['receivers'],batch['node_features']\n",
    "\n",
    "        target_seq = target_seq.squeeze(0)                    # [T,N,out_dim]\n",
    "        senders = senders.squeeze(0)\n",
    "        receivers = receivers.squeeze(0)\n",
    "\n",
    "        node_features_seq = node_features_seq.squeeze(0)        # [T, N, F]\n",
    "        time_diff = node_features_seq[1:] - node_features_seq[:-1]\n",
    "        dynamic_mask = time_diff.abs().max(dim=0).values > 1e-6 # [N, F]\n",
    "        dynamic_mask = dynamic_mask.any(dim=0)                  # [F]\n",
    "        static_idx = (~dynamic_mask).nonzero(as_tuple=True)[0]\n",
    "        dynamic_idx = dynamic_mask.nonzero(as_tuple=True)[0]\n",
    "\n",
    "        static_feat = node_features_seq[0, :, static_idx]                     # [N, static_dim]\n",
    "        dynamic_seq = node_features_seq[:, :, dynamic_idx]                    # [T, N, dynamic_dim]\n",
    "        state_dim = dynamic_seq.size(-1) // 2\n",
    "        state_seq = dynamic_seq[:, :, :state_dim]\n",
    "        cond_seq = dynamic_seq[:, :, state_dim:]\n",
    "\n",
    "        state_init = state_seq[0]\n",
    "        known_cond = cond_seq[:-1]          # length T-1 aligns with transitions\n",
    "        target_states = state_seq[1:]       # ground truth next states\n",
    "        \n",
    "        #print(state_init.shape,known_cond.shape,static_feat.shape,edge_features[0].shape,senders.shape,receivers.shape)\n",
    "        preds = gn.rollout(state_init, known_cond, static_feat, edge_features[0], senders, receivers)\n",
    "        loss = loss_fn(preds, target_states)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        #print(total_loss)\n",
    "    losses.append(total_loss)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss={total_loss/len(loader):.4f}\")\n",
    "torch.save({'model':gn.state_dict(),'optimizer':optimizer.state_dict()},'torchfem_dataset/weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3ce0d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('Losses')\n",
    "plt.ylabel('Smooth L1')\n",
    "plt.plot(losses,'k')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xlim(0,len(losses)-1)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('torchfem_dataset/losses.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DiffPool\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "def build_dense_adj(senders: torch.Tensor, receivers: torch.Tensor, num_nodes: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Builds a symmetric adjacency matrix for a single graph.\n",
    "    \"\"\"\n",
    "    adj = torch.zeros(num_nodes, num_nodes, device=senders.device)\n",
    "    adj[senders, receivers] = 1.0\n",
    "    adj[receivers, senders] = 1.0\n",
    "    adj.fill_diagonal_(1.0)\n",
    "    return adj\n",
    "\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Lightweight message-passing block used both for embeddings and assignments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, node_dim: int, edge_dim: int, hidden_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        nodes: torch.Tensor,\n",
    "        edge_attr: torch.Tensor,\n",
    "        senders: torch.Tensor,\n",
    "        receivers: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        msg_input = torch.cat([nodes[senders], edge_attr], dim=-1)\n",
    "        messages = self.edge_mlp(msg_input)\n",
    "\n",
    "        agg = torch.zeros(nodes.size(0), messages.size(-1), device=nodes.device)\n",
    "        agg.index_add_(0, receivers, messages)\n",
    "\n",
    "        node_input = torch.cat([nodes, agg], dim=-1)\n",
    "        return self.node_mlp(node_input)\n",
    "\n",
    "\n",
    "class DiffPoolLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Single DiffPool layer: learns cluster assignments and pooled embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        edge_dim: int,\n",
    "        hidden_dim: int,\n",
    "        assign_dim: int,\n",
    "        clusters: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_gnn = GraphConv(input_dim, edge_dim, hidden_dim, hidden_dim)\n",
    "        self.assign_gnn = GraphConv(input_dim, edge_dim, hidden_dim, clusters)\n",
    "        self.assign_proj = nn.Linear(clusters, assign_dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        nodes: torch.Tensor,\n",
    "        adj: torch.Tensor,\n",
    "        edge_attr: torch.Tensor,\n",
    "        senders: torch.Tensor,\n",
    "        receivers: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        z = self.embed_gnn(nodes, edge_attr, senders, receivers)\n",
    "        s_logits = self.assign_gnn(nodes, edge_attr, senders, receivers)\n",
    "        s = torch.softmax(s_logits, dim=-1)\n",
    "\n",
    "        x_pooled = torch.matmul(s.transpose(0, 1), z)\n",
    "        adj_pooled = torch.matmul(torch.matmul(s.transpose(0, 1), adj), s)\n",
    "\n",
    "        info = {\n",
    "            \"assign_logits\": s_logits,\n",
    "            \"assign_soft\": s,\n",
    "            \"node_embed\": z,\n",
    "        }\n",
    "        return x_pooled, adj_pooled, info\n",
    "\n",
    "\n",
    "class GraphTemporalDiffPool(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal forecaster with DiffPool for graph-level compression.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_dim: int,\n",
    "        edge_dim: int,\n",
    "        hidden_dim: int,\n",
    "        out_dim: int,\n",
    "        clusters: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pre_gnn = GraphConv(node_dim, edge_dim, hidden_dim, hidden_dim)\n",
    "        self.pool = DiffPoolLayer(hidden_dim, edge_dim, hidden_dim, hidden_dim, clusters)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=hidden_dim * clusters,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_t: torch.Tensor,\n",
    "        edge_attr: torch.Tensor,\n",
    "        senders: torch.Tensor,\n",
    "        receivers: torch.Tensor,\n",
    "        state: Tuple[torch.Tensor, torch.Tensor] | None = None,\n",
    "    ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor], Dict[str, torch.Tensor]]:\n",
    "        pooled_repr = []\n",
    "        pool_info: Dict[str, torch.Tensor] = {}\n",
    "\n",
    "        for b in range(x_t.size(0)):\n",
    "            nodes = self.pre_gnn(x_t[b], edge_attr[b], senders[b], receivers[b])\n",
    "\n",
    "            adj = build_dense_adj(senders[b], receivers[b], nodes.size(0))\n",
    "            x_pool, _, info = self.pool(\n",
    "                nodes,\n",
    "                adj,\n",
    "                edge_attr[b],\n",
    "                senders[b],\n",
    "                receivers[b],\n",
    "            )\n",
    "\n",
    "            pooled_repr.append(x_pool.reshape(-1))\n",
    "            if b == 0:\n",
    "                pool_info = {k: v.detach() for k, v in info.items()}\n",
    "\n",
    "        rnn_in = torch.stack(pooled_repr, dim=0).unsqueeze(1)\n",
    "\n",
    "        if state is None:\n",
    "            rnn_out, state = self.rnn(rnn_in)\n",
    "        else:\n",
    "            rnn_out, state = self.rnn(rnn_in, state)\n",
    "\n",
    "        preds = self.decoder(rnn_out.squeeze(1))\n",
    "        return preds, state, pool_info\n",
    "\n",
    "    def rollout(\n",
    "        self,\n",
    "        node_init: torch.Tensor,\n",
    "        edge_attr: torch.Tensor,\n",
    "        senders: torch.Tensor,\n",
    "        receivers: torch.Tensor,\n",
    "        steps: int,\n",
    "    ) -> torch.Tensor:\n",
    "        preds = []\n",
    "        x_t = node_init\n",
    "        state = None\n",
    "\n",
    "        for _ in range(steps):\n",
    "            x_t, state, _ = self.forward(x_t, edge_attr, senders, receivers, state)\n",
    "            preds.append(x_t)\n",
    "\n",
    "        return torch.stack(preds, dim=1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    batch_size, num_nodes, node_dim = 1, 6, 4\n",
    "    edge_dim, clusters = 3, 3\n",
    "    out_dim, rollout_steps = node_dim, 5\n",
    "\n",
    "    node_features = torch.randn(batch_size, num_nodes, node_dim)\n",
    "\n",
    "    edge_list = []\n",
    "    for i in range(num_nodes):\n",
    "        j = (i + 1) % num_nodes\n",
    "        edge_list.append((i, j))\n",
    "        edge_list.append((j, i))\n",
    "\n",
    "    senders = torch.tensor([s for s, _ in edge_list]).unsqueeze(0)\n",
    "    receivers = torch.tensor([r for _, r in edge_list]).unsqueeze(0)\n",
    "    edge_features = torch.randn(batch_size, len(edge_list), edge_dim)\n",
    "\n",
    "    model = GraphTemporalDiffPool(\n",
    "        node_dim=node_dim,\n",
    "        edge_dim=edge_dim,\n",
    "        hidden_dim=32,\n",
    "        out_dim=out_dim,\n",
    "        clusters=clusters,\n",
    "    )\n",
    "\n",
    "    out, _, info = model(node_features, edge_features, senders, receivers)\n",
    "    print(\"Single step output:\", out.shape)\n",
    "    print(\"Assignment matrix example:\", info[\"assign_soft\"].shape)\n",
    "\n",
    "    preds = model.rollout(\n",
    "        node_features,\n",
    "        edge_features,\n",
    "        senders,\n",
    "        receivers,\n",
    "        steps=rollout_steps,\n",
    "    )\n",
    "    print(\"Rollout output:\", preds.shape)\n",
    "\n",
    "    # Expand: swap synthetic data with the real FEM dataset loader, add batching >1,\n",
    "    #         and plug the pooled embeddings into your training loop with losses/metrics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
